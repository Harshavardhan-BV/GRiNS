{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Gene Regulatory Interaction Network Simulator (GRiNS)","text":"<p>A Python library for simulating gene regulatory networks (GRNs) using parameter-agnostic frameworks like RACIPE and Ising formalism, with GPU acceleration and efficient ODE solving.</p> <p>Modeling gene regulatory networks (GRNs) is essential for understanding cellular processes, but parameterizing these networks becomes increasingly difficult as they scale. This Python library provides a simulation framework that unifies parameter-agnostic approaches, including RACIPE and Ising formalism, into a single, flexible tool.  </p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Simulation Frameworks: Supports both ODE-based (RACIPE) and coarse-grained (Ising formalism) methods for studying GRN dynamics.  </li> <li>Parameter-Agnostic Modeling: Translates network topology into mathematical models without requiring detailed parameter tuning.  </li> <li>Scalable Computation: Uses the Jax ecosystem for GPU acceleration and Diffrax for efficient ODE solving.  </li> <li>Data Processing Tools: Provides normalization and discretization functions to standardize simulation outputs for downstream analysis.  </li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#gpu-version-installation-recommended","title":"GPU Version Installation (Recommended)","text":"<p>For optimal performance, it is recommended to install the GPU-accelerated version of the library. This version leverages CUDA for faster computations, making it well-suited for large-scale simulations. If you have a compatible NVIDIA GPU, install the library with:  </p> <pre><code>pip install grins[cuda12]\n</code></pre>"},{"location":"#cpu-version-installation","title":"CPU Version Installation","text":"<p>If you do not have a compatible GPU, you can install the CPU version instead:</p> <pre><code>pip install grins\n</code></pre> <p>Compared to the GPU version, the CPU version will be slower, especially for large simulations.</p>"},{"location":"#citation","title":"Citation","text":""},{"location":"api/IsingBoolean/","title":"Ising Boolean Formalism","text":"<p>Functions related to Ising simulation.</p>"},{"location":"api/IsingBoolean/#grn-parsing-and-inital-condition-generation-functions","title":"GRN Parsing and Inital Condition Generation Functions","text":""},{"location":"api/IsingBoolean/#grins.ising_bool.parse_topo_to_matrix","title":"<code>grins.ising_bool.parse_topo_to_matrix(topofile_path)</code>","text":"<p>Parses a topology file into an adjacency matrix.</p> <p>This function reads a topology file, and converts it into an adjacency matrix. The adjacency matrix is then converted to a JAX array.</p> <p>Parameters:</p> <ul> <li> <code>topofile_path</code>               (<code>str</code>)           \u2013            <p>The path to the topology file. The file should be in a format readable by pandas <code>read_csv</code> with whitespace as the delimiter.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>A tuple containing: topo_adj : jax.numpy.ndarray     The adjacency matrix as a JAX array. node_names : list     A list of node names in the order they appear in the adjacency matrix.</p> </li> </ul> Source code in <code>grins/ising_bool.py</code> <pre><code>def parse_topo_to_matrix(topofile_path):\n    \"\"\"\n    Parses a topology file into an adjacency matrix.\n\n    This function reads a topology file, and converts it into an adjacency matrix.\n    The adjacency matrix is then converted to a JAX array.\n\n    Parameters\n    ----------\n    topofile_path : str\n        The path to the topology file. The file should be in a format readable by pandas ```read_csv``` with whitespace as the delimiter.\n\n    Returns\n    -------\n    tuple\n        A tuple containing:\n        topo_adj : jax.numpy.ndarray\n            The adjacency matrix as a JAX array.\n        node_names : list\n            A list of node names in the order they appear in the adjacency matrix.\n    \"\"\"\n    # Read the topo file as a pandas dataframe\n    topo_df = pd.read_csv(topofile_path, sep=r\"\\s+\")\n    # Get the node names\n    node_names = set(\n        list(topo_df[\"Source\"].unique()) + list(topo_df[\"Target\"].unique())\n    )\n    # Adding self loops with type 0 for all the nodes if self loop of that node is not present\n    # This is done to ensure that the adjacency matrix is square i.e all the only target or source nodes are also included\n    # Subsetting the dataframe to get the self loops\n    self_loops = topo_df[topo_df[\"Source\"] == topo_df[\"Target\"]]\n    # Getting the list of nodes without self loops\n    nodes_without_self_loops = list(node_names - set(self_loops[\"Source\"]))\n    # Creating a dataframe for the nodes without self loops\n    self_loops_df = pd.DataFrame(\n        [\n            nodes_without_self_loops,\n            nodes_without_self_loops,\n            [0] * len(nodes_without_self_loops),\n        ]\n    ).T\n    # Renaming the columns\n    self_loops_df.columns = [\"Source\", \"Target\", \"Type\"]\n    # Adding the self loops to the topo dataframe\n    topo_df = pd.concat([topo_df, self_loops_df], ignore_index=True)\n    # Convert the type column to float\n    topo_df[\"Type\"] = topo_df[\"Type\"].astype(float)\n    # Replacing the 2s with -1s\n    topo_df[\"Type\"] = topo_df[\"Type\"].replace({2: -1})\n    # Pivot the dataframe to get the adjacencey matrix\n    topo_df = topo_df.pivot(index=\"Source\", columns=\"Target\", values=\"Type\")\n    # Make the node names set into a list\n    node_names = sorted(list(node_names))\n    # Reorder the columns and rows\n    topo_df = topo_df.loc[node_names, node_names]\n    # Replace the NaN values with 0s\n    topo_df.fillna(0, inplace=True)\n    # Convert the dataframe to a numpy adjacency matrix\n    topo_adj = topo_df.to_numpy()\n    # Convert the adjacency matrix to a jax array\n    topo_adj = jnp.array(topo_adj, dtype=jnp.int16)\n    return topo_adj, node_names\n</code></pre>"},{"location":"api/IsingBoolean/#grins.ising_bool.generate_intial_conditions","title":"<code>grins.ising_bool.generate_intial_conditions(num_nodes, num_samples)</code>","text":"<p>Generate initial conditions for a given number of nodes and samples.</p> <p>This function generates initial conditions using Sobol sequences and scales the generated samples to [0, 1].</p> <p>Parameters:</p> <ul> <li> <code>num_nodes</code>               (<code>int</code>)           \u2013            <p>The number of nodes for which to generate initial conditions.</p> </li> <li> <code>num_samples</code>               (<code>int</code>)           \u2013            <p>The number of samples to generate.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The generated initial conditions as a JAX array of integers.</p> </li> </ul> Source code in <code>grins/ising_bool.py</code> <pre><code>def generate_intial_conditions(num_nodes, num_samples):\n    \"\"\"\n    Generate initial conditions for a given number of nodes and samples.\n\n    This function generates initial conditions using Sobol sequences and scales the generated samples to [0, 1].\n\n    Parameters\n    ----------\n    num_nodes : int\n        The number of nodes for which to generate initial conditions.\n    num_samples : int\n        The number of samples to generate.\n\n    Returns\n    -------\n    jax.numpy.ndarray\n        The generated initial conditions as a JAX array of integers.\n    \"\"\"\n\n    # Internal function to generate sobol sequences\n    def _gen_sobol_seq(dimensions, num_samples, optimise=False):\n        \"\"\"\n        Generate Sobol sequence samples.\n\n        Parameters\n        ----------\n        dimensions : int\n            The number of dimensions for the Sobol sequence.\n        num_samples : int\n            The number of samples to generate.\n        optimise : bool, optional\n            Whether to use optimization for generation. Defaults to False.\n\n        Returns\n        -------\n        numpy.ndarray\n            The generated Sobol sequence samples.\n        \"\"\"\n        if not optimise:\n            samples = qmc.Sobol(d=dimensions, scramble=True).random(num_samples)\n        else:\n            # Optimisation leads to a significant slowdown in the generation\n            # Use only if needed\n            samples = qmc.Sobol(\n                d=dimensions, scramble=True, optimization=\"lloyd\"\n            ).random(num_samples)\n        return samples\n\n    # Function which scales a given distribution to the required ranges\n    def _scale_distribution(\n        sample,\n        minmax_vals,\n        round_int=False,\n    ):\n        \"\"\"\n        Scale the given distribution to the required ranges.\n\n        Parameters\n        ----------\n        sample : numpy.ndarray\n            The distribution to be scaled.\n        minmax_vals : tuple\n            The minimum and maximum values for scaling.\n        round_int : bool, optional\n            Whether to round the values to the nearest integer. Defaults to False.\n\n        Returns\n        -------\n        numpy.ndarray\n            The scaled distribution.\n        \"\"\"\n        min_vals = minmax_vals[:, 0]\n        max_vals = minmax_vals[:, 1]\n        if round_int:\n            min_vals = min_vals - 1\n        # Scaling the values for the log distributions\n        sample = min_vals + (max_vals - min_vals) * (\n            sample - np.min(sample, axis=0)\n        ) / (np.max(sample, axis=0) - np.min(sample, axis=0))\n        # If round is required, return the scaled and rounded values\n        if round_int:\n            # Rounding the values to the next integer\n            sample = np.ceil(sample)\n            # # If values are present below the minimum value, shift them to the minimum value\n            # If values are present above the maximum value, shift them to the maximum value\n            sample = np.clip(sample, min_vals + 1, max_vals)\n            # # Convert the values to integers\n            sample = sample.astype(int)\n            return sample\n        else:\n            return sample\n\n    # Generate the MinMax values\n    minmax_vals = np.array([[0, 1]] * num_nodes)\n    # Generate the Sobol sequences\n    unscaled_samples = _gen_sobol_seq(len(minmax_vals), num_samples)\n    # Scaling the samples\n    scaled_samples = _scale_distribution(\n        unscaled_samples, np.array(minmax_vals), round_int=True\n    )\n    # COnvert the jax array\n    scaled_samples = jnp.array(scaled_samples, dtype=jnp.int16)\n    return scaled_samples\n</code></pre>"},{"location":"api/IsingBoolean/#ising-boolean-simulation-functions","title":"Ising Boolean Simulation Functions","text":""},{"location":"api/IsingBoolean/#grins.ising_bool.sync_eval_next_state","title":"<code>grins.ising_bool.sync_eval_next_state(prev_state, topo_adj, replacement_values)</code>","text":"<p>Evaluate the next state of a system synchronously based on the previous state, topology adjacency matrix, and replacement values.</p> <p>Parameters:</p> <ul> <li> <code>prev_state</code>               (<code>ndarray</code>)           \u2013            <p>The previous state of the system.</p> </li> <li> <code>topo_adj</code>               (<code>ndarray</code>)           \u2013            <p>The topology adjacency matrix representing the connections between nodes in the system.</p> </li> <li> <code>replacement_values</code>               (<code>ndarray</code>)           \u2013            <p>A vector of two values used for replacement based on the computed state conditions. The values are: [value_if_negative, value_if_positive]. Value of 0 is not included as it is assumed that the state will remain the same if the node evaluates to 0 in that step. prev_state (jnp.ndarray): The previous state of the system.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The new state of the system as an array of int16.</p> </li> </ul> Source code in <code>grins/ising_bool.py</code> <pre><code>@jit\ndef sync_eval_next_state(\n    prev_state,\n    topo_adj,\n    replacement_values,  # Vector of three values\n):\n    \"\"\"\n    Evaluate the next state of a system synchronously based on the previous state,\n    topology adjacency matrix, and replacement values.\n\n    Parameters\n    ----------\n    prev_state : jnp.ndarray\n        The previous state of the system.\n    topo_adj : jnp.ndarray\n        The topology adjacency matrix representing the connections between nodes in the system.\n    replacement_values : jnp.ndarray\n        A vector of two values used for replacement based on the computed state conditions. The values are: [value_if_negative, value_if_positive].\n        Value of 0 is not included as it is assumed that the state will remain the same if the node evaluates to 0 in that step.\n        prev_state (jnp.ndarray): The previous state of the system.\n\n    Returns\n    -------\n    jnp.ndarray\n        The new state of the system as an array of int16.\n    \"\"\"\n    # Compute the state of the incoming links for the state\n    new_state = jnp.dot(prev_state, topo_adj)\n    # debug.print(\"Scaled state: {}\", new_state)\n    # Apply replacement values based on conditions\n    new_state = jnp.where(\n        new_state &lt; 0,\n        replacement_values[0],\n        jnp.where(new_state &gt; 0, replacement_values[1], prev_state),\n    )\n    # Convert the new state to int16\n    new_state = new_state.astype(jnp.int16)\n    return new_state\n</code></pre>"},{"location":"api/IsingBoolean/#grins.ising_bool.simulate_sync_trajectory","title":"<code>grins.ising_bool.simulate_sync_trajectory(initial_condition, topo_adj, replacement_values, max_steps)</code>","text":"<p>Simulates a synchronous trajectory of a system based on the given initial condition, topology adjacency matrix, and replacement values.</p> <p>Parameters:</p> <ul> <li> <code>initial_condition</code>               (<code>ndarray</code>)           \u2013            <p>The initial state of the system.</p> </li> <li> <code>topo_adj</code>               (<code>ndarray</code>)           \u2013            <p>The topology adjacency matrix representing the connections between nodes in the system.</p> </li> <li> <code>replacement_values</code>               (<code>ndarray</code>)           \u2013            <p>The values used to replace the states during the simulation. It is a vector of two values in the form [value_if_negative, value_if_positive].</p> </li> <li> <code>max_steps</code>               (<code>arange</code>)           \u2013            <p>The range of steps to simulate. The simulation will run for each step in the range.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A JAX array containing the states of the system at each step, with the initial condition included at the beginning. The array also includes a column for the step indices. All -1 values in the states are replaced with 0 if the replacement values are [-1, 1].</p> </li> </ul> Source code in <code>grins/ising_bool.py</code> <pre><code>@jit\ndef simulate_sync_trajectory(\n    initial_condition,\n    topo_adj,\n    replacement_values,\n    max_steps,\n):\n    \"\"\"\n    Simulates a synchronous trajectory of a system based on the given initial condition, topology adjacency matrix, and replacement values.\n\n    Parameters\n    ----------\n    initial_condition : jnp.ndarray\n        The initial state of the system.\n    topo_adj : jnp.ndarray\n        The topology adjacency matrix representing the connections between nodes in the system.\n    replacement_values : jnp.ndarray\n        The values used to replace the states during the simulation. It is a vector of two values in the form [value_if_negative, value_if_positive].\n    max_steps : jnp.arange\n        The range of steps to simulate. The simulation will run for each step in the range.\n\n    Returns\n    -------\n    jnp.ndarray\n        A JAX array containing the states of the system at each step, with the initial condition included at the beginning. The array also includes a column for the step indices. All -1 values in the states are replaced with 0 if the replacement values are [-1, 1].\n    \"\"\"\n\n    # Initialize states array\n    def step_fn(carry, _):\n        current_state = carry\n        next_state = sync_eval_next_state(\n            current_state,\n            topo_adj,\n            replacement_values,\n        )\n        return next_state, next_state\n\n    # Run the simulation loop\n    _, states = lax.scan(step_fn, initial_condition, xs=max_steps)\n    # Add the initial condition to the states at the beginning\n    states = jnp.concatenate((jnp.expand_dims(initial_condition, axis=0), states))\n    # Add a column for the steps\n    states = jnp.hstack((jnp.arange(states.shape[0]).reshape(-1, 1), states))\n    # Make sure that states are a jax array\n    states = jnp.array(states, dtype=jnp.int16)\n    # For the results where the replacement values are -1 and 1, some nodes will have -1 values, but for all purposes those should be considered as 0 values, so turning all -1 values to 0\n    states = jnp.where(states == -1, 0, states)\n    return states\n</code></pre>"},{"location":"api/IsingBoolean/#grins.ising_bool.async_eval_next_state","title":"<code>grins.ising_bool.async_eval_next_state(prev_state, topo_adj, replacement_values, update_index)</code>","text":"<p>Asynchronously evaluates the next state of a node in an Ising model.</p> <p>Parameters:</p> <ul> <li> <code>prev_state</code>               (<code>ndarray</code>)           \u2013            <p>The previous state vector of the system.</p> </li> <li> <code>topo_adj</code>               (<code>ndarray</code>)           \u2013            <p>The adjacency matrix representing the topology of the system.</p> </li> <li> <code>replacement_values</code>               (<code>ndarray</code>)           \u2013            <p>A vector of two values used for state replacement based on conditions. The values of the vector should be [value_if_negative, value_if_positive]. The value for 0 is not included as it is assumed that the state will remain the same if the node evaluates to 0 in that step.</p> </li> <li> <code>update_index</code>               (<code>int</code>)           \u2013            <p>The index of the node to update.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The new state vector after updating the specified node.</p> </li> </ul> Source code in <code>grins/ising_bool.py</code> <pre><code>@jit\ndef async_eval_next_state(\n    prev_state,\n    topo_adj,\n    replacement_values,  # Vector of two values\n    update_index,  # Index of the node to update\n):\n    \"\"\"\n    Asynchronously evaluates the next state of a node in an Ising model.\n\n    Parameters\n    ----------\n    prev_state : jnp.ndarray\n        The previous state vector of the system.\n    topo_adj : jnp.ndarray\n        The adjacency matrix representing the topology of the system.\n    replacement_values : jnp.ndarray\n        A vector of two values used for state replacement based on conditions. The values of the vector should be [value_if_negative, value_if_positive]. The value for 0 is not included as it is assumed that the state will remain the same if the node evaluates to 0 in that step.\n    update_index : int\n        The index of the node to update.\n\n    Returns\n    -------\n    jnp.ndarray\n        The new state vector after updating the specified node.\n    \"\"\"\n    # debug.print(\"Update index: {}\", update_index)\n    # debug.print(\"Prev state: {}\", prev_state)\n    # Compute the state update only for the selected index\n    new_value = jnp.dot(prev_state, topo_adj[update_index])  # Only update one row\n    # debug.print(\"New value0: {}\", new_value)\n    # Apply replacement values based on conditions\n    new_value = jnp.where(\n        new_value &lt; 0,\n        replacement_values[0],\n        jnp.where(new_value &gt; 0, replacement_values[1], prev_state[update_index]),\n    ).astype(jnp.int16)\n    # debug.print(\"New value1: {}\", new_value)\n    # Scatter the updated value into the state vector\n    new_state = prev_state.at[update_index].set(new_value)\n    # debug.print(\"New state: {}\", new_state)\n    return new_state\n</code></pre>"},{"location":"api/IsingBoolean/#grins.ising_bool.simulate_async_trajectory","title":"<code>grins.ising_bool.simulate_async_trajectory(initial_condition, topo_adj, replacement_values, update_indices)</code>","text":"<p>Simulates an asynchronous trajectory of a system given an initial condition and update indices.</p> <p>Parameters:</p> <ul> <li> <code>initial_condition</code>               (<code>ndarray</code>)           \u2013            <p>The initial condition of the system.</p> </li> <li> <code>topo_adj</code>               (<code>ndarray</code>)           \u2013            <p>The adjacency matrix representing the topology of the system.</p> </li> <li> <code>replacement_values</code>               (<code>ndarray</code>)           \u2013            <p>The values used to replace the states during the simulation. It is a vector of two values in the form [value_if_negative, value_if_positive].</p> </li> <li> <code>update_indices</code>               (<code>ndarray</code>)           \u2013            <p>A vector of indices specifying which node to update at each step. The length of the vector should be equal to the number of steps. If not, the simulation will only run until the length of the update_indices.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A JAX array containing the states of the system at each step, with the initial condition included at the beginning. The array also includes a column for the step indices. All -1 values in the states are replaced with 0 if the replacement values are [-1, 1].</p> </li> </ul> Source code in <code>grins/ising_bool.py</code> <pre><code>@jit\ndef simulate_async_trajectory(\n    initial_condition,\n    topo_adj,\n    replacement_values,\n    update_indices,  # Vector of indices specifying which node to update at each step\n):\n    \"\"\"\n    Simulates an asynchronous trajectory of a system given an initial condition and update indices.\n\n    Parameters\n    ----------\n    initial_condition : jnp.ndarray\n        The initial condition of the system.\n    topo_adj : jnp.ndarray\n        The adjacency matrix representing the topology of the system.\n    replacement_values : jnp.ndarray\n        The values used to replace the states during the simulation. It is a vector of two values in the form [value_if_negative, value_if_positive].\n    update_indices : jnp.ndarray\n        A vector of indices specifying which node to update at each step. The length of the vector should be equal to the number of steps. If not, the simulation will only run until the length of the update_indices.\n\n    Returns\n    -------\n    jnp.ndarray\n        A JAX array containing the states of the system at each step, with the initial condition included at the beginning. The array also includes a column for the step indices. All -1 values in the states are replaced with 0 if the replacement values are [-1, 1].\n    \"\"\"\n\n    def step_fn(carry, update_index):\n        next_state = async_eval_next_state(\n            carry,\n            topo_adj,\n            replacement_values,\n            update_index,\n        )\n        return next_state, next_state\n\n    # Run the simulation loop, passing update_indices as xs\n    _, states = lax.scan(step_fn, initial_condition, xs=update_indices)\n    # Add the initial condition to the states at the beginning\n    states = jnp.concatenate((jnp.expand_dims(initial_condition, axis=0), states))\n    # Add a column for the steps\n    states = jnp.hstack((jnp.arange(states.shape[0]).reshape(-1, 1), states))\n    # Make sure that states are the right dtype\n    states = jnp.array(states, dtype=jnp.int16)\n    # For the results where the replacement values are -1 and 1, some nodes will have -1 values, but for all purposes those should be considered as 0 values, so turning all -1 values to 0\n    states = jnp.where(states == -1, 0, states)\n    return states\n</code></pre>"},{"location":"api/IsingBoolean/#grins.ising_bool.run_simulations","title":"<code>grins.ising_bool.run_simulations(topo_file, num_initial_conditions=None, inital_conditions=None, max_steps=None, batch_size=None, replacement_values=jnp.array([0, 1]), mode='sync', packbits=False, save_dir='IsingSimulResults')</code>","text":"<p>Run synchronous or asynchronous simulations for a given topology.</p> <p>Parameters:</p> <ul> <li> <code>topo_file</code>               (<code>str</code>)           \u2013            <p>The path to the topology file.</p> </li> <li> <code>num_initial_conditions</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The number of initial conditions to sample. If not provided, the default is 2**10.</p> </li> <li> <code>inital_conditions</code>               (<code>ndarray</code>, default:                   <code>None</code> )           \u2013            <p>The initial conditions matrix with the individual initial conditions as rows of the matrix. If provided, num_initial_conditions is ignored.</p> </li> <li> <code>max_steps</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The maximum number of steps to simulate. If not provided, it is calculated to be 10 times the number of nodes.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The number of samples per batch. If not provided, the default is 2**10.</p> </li> <li> <code>replacement_values</code>               (<code>ndarray</code>, default:                   <code>array([0, 1])</code> )           \u2013            <p>The values used for replacement in the simulation. The default is [0, 1].</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'sync'</code> )           \u2013            <p>The simulation mode, either \"sync\" or \"async\". The default is \"sync\".</p> </li> <li> <code>packbits</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to pack the 0/1 states into bits to reduce memory usage. The default is False.</p> </li> <li> <code>save_dir</code>               (<code>str</code>, default:                   <code>'IsingSimulResults'</code> )           \u2013            <p>The directory to save the simulation results. The default is \"IsingSimulResults\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>The simulation results are saved to a parquet file in save_dir within a subdirectory named after the topology file.</p> </li> </ul> Example <p>Run the synchronous simulation for a topology file:</p> <pre><code>&gt;&gt;&gt; run_simulations(\n...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n...     num_initial_conditions=2**10,\n...     max_steps=100,\n...     batch_size=2**10,\n...     replacement_values=jnp.array([0, 1]),\n...     mode=\"sync\",\n...     packbits=True,\n...     save_dir=\"IsingSimulResults\",\n... )\n</code></pre> <p>This will save the simulation results to a parquet file in the directory \"IsingSimulResults/ER_1000_0.1/ER_1000_0.1_sync_results.parquet\".</p> <p>Similary, the asynchronous simulation can be run by setting mode=\"async\".</p> <p>If the initial conditions matrix is provided, the num_initial_conditions parameter is ignored. In this case, the initial_conditions matrix should have the individual initial conditions as rows. If only specfic inital conditions are to be used, the initial conditions matrix can be provided with the individual initial conditions as rows of the matrix. This provides control over simulating specific pre-defined initial conditions.</p> <pre><code>&gt;&gt;&gt; initial_conditions = jnp.array([[0, 1, 0, 1], [1, 0, 1, 0], [0, 0, 1, 1]])\n&gt;&gt;&gt; run_simulations(\n...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n...     initial_conditions=initial_conditions,\n...     max_steps=100,\n...     batch_size=2**10,\n...     replacement_values=jnp.array([0, 1]),\n...     mode=\"sync\",\n...     packbits=True,\n...     save_dir=\"IsingSimulResults\",\n... )\n</code></pre> <p>For cases where the replacement values are not [0, 1], the replacement values should be provided as a jax array of length 2 with the first value less than the second.</p> <pre><code>&gt;&gt;&gt; replacement_values = jnp.array([-1, 1]) # Replacement values are -1 for negetive and 1 for positive\n&gt;&gt;&gt; run_simulations(\n...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n...     num_initial_conditions=2**10,\n...     max_steps=100,\n...     batch_size=2**10,\n...     replacement_values=replacement_values,\n...     mode=\"sync\",\n...     packbits=True,\n...     save_dir=\"IsingSimulResults\",\n... )\n</code></pre> <p>The results for [-1, 1] replacment values will also be converted to 0 for all the -1 or 0 values in the states and 1s will remain as 1s when saving to the file. This is important as otherwise the packbits  would not work.</p> <p>The packbits function used is jnp.packbits which packs the 0/1 states into bits to reduce memory usage. This is useful when the number of nodes is large and the number of steps is also large. The memory usase can be reduced by a factor of 8 by packing the states into bits. If packbits is not set to True, the states are saved as is.</p> <pre><code>&gt;&gt;&gt; run_simulations(\n...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n...     num_initial_conditions=2**10,\n...     max_steps=100,\n...     batch_size=2**10,\n...     replacement_values=jnp.array([0, 1]),\n...     mode=\"sync\",\n...     packbits=False,\n...     save_dir=\"IsingSimulResults\",\n... )\n</code></pre> <p>The final dataframe which is written to the parquet file has the following columns for the packbits=False case: - Step: The step number for the simulation. - Node names: The names of the nodes in the network. If the packbits=True, the final dataframe has the following columns: - Step: The step number for the simulation. - Byte_i: The ith byte of the packed states for the simulation. The Byte_i columns are created based on the number of nodes in the network. For example, if there are 100 nodes, there will be 13 columns for the packed states. They can be unpacked using jnp.unpackbits to get the unpacked state values. The order of the nodes for the Byte_i columns is the same as the order of the nodes in the network after parsing the topology file using the parse_topo_to_matrix function. The order of the nodes is saved in a text file in the simulation directory for easy reference. The naming convention for the text file is toponame_node_names_order.csv.</p> Source code in <code>grins/ising_bool.py</code> <pre><code>def run_simulations(\n    topo_file,\n    num_initial_conditions=None,\n    inital_conditions=None,\n    max_steps=None,\n    batch_size=None,\n    replacement_values=jnp.array([0, 1]),\n    mode=\"sync\",\n    packbits=False,\n    save_dir=\"IsingSimulResults\",\n):\n    \"\"\"\n    Run synchronous or asynchronous simulations for a given topology.\n\n    Parameters\n    ----------\n    topo_file : str\n        The path to the topology file.\n    num_initial_conditions : int, optional\n        The number of initial conditions to sample. If not provided, the default is 2**10.\n    inital_conditions : jax.numpy.ndarray, optional\n        The initial conditions matrix with the individual initial conditions as rows of the matrix. If provided, num_initial_conditions is ignored.\n    max_steps : int, optional\n        The maximum number of steps to simulate. If not provided, it is calculated to be 10 times the number of nodes.\n    batch_size : int, optional\n        The number of samples per batch. If not provided, the default is 2**10.\n    replacement_values : jax.numpy.ndarray, optional\n        The values used for replacement in the simulation. The default is [0, 1].\n    mode : str, optional\n        The simulation mode, either \"sync\" or \"async\". The default is \"sync\".\n    packbits : bool, optional\n        Whether to pack the 0/1 states into bits to reduce memory usage. The default is False.\n    save_dir : str, optional\n        The directory to save the simulation results. The default is \"IsingSimulResults\".\n\n    Returns\n    -------\n    None\n        The simulation results are saved to a parquet file in save_dir within a subdirectory named after the topology file.\n\n    Example\n    -------\n    Run the synchronous simulation for a topology file:\n\n        &gt;&gt;&gt; run_simulations(\n        ...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n        ...     num_initial_conditions=2**10,\n        ...     max_steps=100,\n        ...     batch_size=2**10,\n        ...     replacement_values=jnp.array([0, 1]),\n        ...     mode=\"sync\",\n        ...     packbits=True,\n        ...     save_dir=\"IsingSimulResults\",\n        ... )\n\n    This will save the simulation results to a parquet file in the directory \"IsingSimulResults/ER_1000_0.1/ER_1000_0.1_sync_results.parquet\".\n\n    Similary, the asynchronous simulation can be run by setting mode=\"async\".\n\n    If the initial conditions matrix is provided, the num_initial_conditions parameter is ignored. In this case, the initial_conditions matrix should have the individual initial conditions as rows.\n    If only specfic inital conditions are to be used, the initial conditions matrix can be provided with the individual initial conditions as rows of the matrix. This provides control over simulating specific pre-defined initial conditions.\n\n        &gt;&gt;&gt; initial_conditions = jnp.array([[0, 1, 0, 1], [1, 0, 1, 0], [0, 0, 1, 1]])\n        &gt;&gt;&gt; run_simulations(\n        ...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n        ...     initial_conditions=initial_conditions,\n        ...     max_steps=100,\n        ...     batch_size=2**10,\n        ...     replacement_values=jnp.array([0, 1]),\n        ...     mode=\"sync\",\n        ...     packbits=True,\n        ...     save_dir=\"IsingSimulResults\",\n        ... )\n\n    For cases where the replacement values are not [0, 1], the replacement values should be provided as a jax array of length 2 with the first value less than the second.\n\n        &gt;&gt;&gt; replacement_values = jnp.array([-1, 1]) # Replacement values are -1 for negetive and 1 for positive\n        &gt;&gt;&gt; run_simulations(\n        ...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n        ...     num_initial_conditions=2**10,\n        ...     max_steps=100,\n        ...     batch_size=2**10,\n        ...     replacement_values=replacement_values,\n        ...     mode=\"sync\",\n        ...     packbits=True,\n        ...     save_dir=\"IsingSimulResults\",\n        ... )\n\n    The results for [-1, 1] replacment values will also be converted to 0 for all the -1 or 0 values in the states and 1s will remain as 1s when saving to the file. This is important as otherwise the packbits  would not work.\n\n    The packbits function used is jnp.packbits which packs the 0/1 states into bits to reduce memory usage. This is useful when the number of nodes is large and the number of steps is also large. The memory usase can be reduced by a factor of 8 by packing the states into bits. If packbits is not set to True, the states are saved as is.\n\n        &gt;&gt;&gt; run_simulations(\n        ...     topo_file=\"TOPOS/ER_1000_0.1.topo\",\n        ...     num_initial_conditions=2**10,\n        ...     max_steps=100,\n        ...     batch_size=2**10,\n        ...     replacement_values=jnp.array([0, 1]),\n        ...     mode=\"sync\",\n        ...     packbits=False,\n        ...     save_dir=\"IsingSimulResults\",\n        ... )\n\n    The final dataframe which is written to the parquet file has the following columns for the packbits=False case:\n    - Step: The step number for the simulation.\n    - Node names: The names of the nodes in the network.\n    If the packbits=True, the final dataframe has the following columns:\n    - Step: The step number for the simulation.\n    - Byte_i: The ith byte of the packed states for the simulation.\n    The Byte_i columns are created based on the number of nodes in the network. For example, if there are 100 nodes, there will be 13 columns for the packed states. They can be unpacked using jnp.unpackbits to get the unpacked state values.\n    The order of the nodes for the Byte_i columns is the same as the order of the nodes in the network after parsing the topology file using the parse_topo_to_matrix function. The order of the nodes is saved in a text file in the simulation directory for easy reference. The naming convention for the text file is toponame_node_names_order.csv.\n    \"\"\"\n    # Create the save directory if it does not exist\n    os.makedirs(save_dir, exist_ok=True)\n    # Create a subdirectory for the topology file\n    topo_name = topo_file.split(\"/\")[-1].split(\".\")[0]\n    sim_dir = f\"{save_dir}/{topo_name}\"\n    os.makedirs(sim_dir, exist_ok=True)\n    # Get the adjacency matrix and node names\n    topo_adj, node_names = parse_topo_to_matrix(topo_file)\n    print(f\"Running {mode} simulations for the network: {topo_file}\")\n    # Default batch size if not specified\n    if batch_size is None:\n        batch_size = 2**10\n    # Default max steps if not specified\n    if max_steps is None:\n        # Determine max steps based on number of nodes\n        max_steps = 10 * len(node_names)\n    # Check if Inital conditions matrix is provided\n    if inital_conditions is None:\n        # Default number of inital conditions if not specified\n        if num_initial_conditions is None:\n            num_initial_conditions = 2**10\n        # Generate random initial conditions\n        initial_conditions = generate_intial_conditions(\n            len(node_names), num_initial_conditions\n        )\n    # Check if the replacement values provided have length 2 and that the first value is less than the second\n    if len(replacement_values) != 2 or replacement_values[0] &gt;= replacement_values[1]:\n        raise ValueError(\n            \"Replacement values must be a jax array of length 2 with the first value less than the second.\"\n        )\n    # Initialize an empty numpy array to store the results\n    if not packbits:\n        results_array = np.empty((0, len(node_names) + 1), dtype=np.int16)\n        # Create the column names for the dataframe\n        df_cols = [\"Step\"] + node_names\n    else:\n        results_array = np.empty(\n            (0, int(np.ceil(len(node_names) / 8)) + 1), dtype=np.int16\n        )\n        # Create the column names for the dataframe\n        df_cols = [\"Step\"] + [\n            f\"Byte_{i}\" for i in range(int(np.ceil(len(node_names) / 8)))\n        ]\n        # Create a text file with the node names seperated by a comma for easy reference\n        with open(f\"{sim_dir}/{topo_name}_node_names_order.csv\", \"w\") as f:\n            f.write(\",\".join(node_names))\n    # Start the simulation timer\n    start_time = time.time()\n    # Run synchronous or asynchronous simulations\n    if mode == \"sync\":\n        # Run synchronous simulations in batches\n        for batch in range(0, num_initial_conditions, batch_size):\n            batch_initial_conditions = initial_conditions[batch : batch + batch_size]\n            batch_results = vmap(\n                lambda x: simulate_sync_trajectory(\n                    x,\n                    topo_adj,\n                    replacement_values,\n                    jnp.arange(max_steps),\n                ),\n                in_axes=0,\n            )(batch_initial_conditions)\n            # Stack the batch results into a single array\n            batch_results = jnp.vstack(batch_results)\n            # If packbits is True, pack the 0/1 states into bits to reduce memory usage\n            if packbits:\n                batch_results = packbit_states(batch_results)\n            # Append the batch results to the main results array\n            results_array = np.vstack((results_array, batch_results))\n\n    elif mode == \"async\":\n        # Generate random update indices for asynchronous updates\n        update_indices_matrix = np.random.randint(\n            0, len(node_names), (max_steps, num_initial_conditions)\n        )\n        update_indices_matrix = jnp.array(update_indices_matrix, dtype=jnp.int16)\n        # Run asynchronous simulations in batches\n        for batch in range(0, num_initial_conditions, batch_size):\n            batch_initial_conditions = initial_conditions[batch : batch + batch_size]\n            batch_update_indices = update_indices_matrix[:, batch : batch + batch_size]\n            batch_states = vmap(\n                lambda x, y: simulate_async_trajectory(\n                    x,\n                    topo_adj,\n                    replacement_values,\n                    y,\n                ),\n                in_axes=(0, 1),\n            )(batch_initial_conditions, batch_update_indices)\n            # Stack the batch results into a single array\n            batch_states = jnp.vstack(batch_states)\n            # If packbits is True, pack the 0/1 states into bits to reduce memory usage\n            if packbits:\n                batch_states = packbit_states(batch_states)\n            # Append the batch results to the main results array\n            results_array = np.vstack((results_array, batch_states))\n\n    # Create a dataframe from the results array\n    results_df = pd.DataFrame(results_array, columns=df_cols)\n    # Saving the results to a parquet file\n    results_df.to_parquet(\n        f\"{sim_dir}/{topo_name}_{mode}_ising_results.parquet\", index=False\n    )\n    # End the simulation timer\n    print(f\"Simulation time for {mode} mode: {time.time() - start_time:.2f} seconds\")\n    return None\n</code></pre>"},{"location":"api/RACIPE/","title":"RACIPE Formalism","text":"<p>Functions related to RACIPE simulation.</p>"},{"location":"api/RACIPE/#grn-parsing-and-ode-generation-functions","title":"GRN Parsing and ODE Generation Functions","text":""},{"location":"api/RACIPE/#grins.reg_funcs.psH","title":"<code>grins.reg_funcs.psH(nod, fld, thr, hill)</code>","text":"<p>Positive Shifted Hill function.</p> <p>Parameters:</p> <ul> <li> <code>nod</code>               (<code>float</code>)           \u2013            <p>The node expression value.</p> </li> <li> <code>fld</code>               (<code>float</code>)           \u2013            <p>The fold change.</p> </li> <li> <code>thr</code>               (<code>float</code>)           \u2013            <p>The half-maximal threshold value.</p> </li> <li> <code>hill</code>               (<code>float</code>)           \u2013            <p>The hill coefficient.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The value of the Positive Shifted Hill function.</p> </li> </ul> Source code in <code>grins/reg_funcs.py</code> <pre><code>def psH(nod, fld, thr, hill):\n    \"\"\"\n    Positive Shifted Hill function.\n\n    Parameters\n    ----------\n    nod : float\n        The node expression value.\n    fld : float\n        The fold change.\n    thr : float\n        The half-maximal threshold value.\n    hill : float\n        The hill coefficient.\n\n    Returns\n    -------\n    float\n        The value of the Positive Shifted Hill function.\n    \"\"\"\n    return (fld + (1 - fld) * (1 / (1 + (nod / thr) ** hill))) / fld\n</code></pre>"},{"location":"api/RACIPE/#grins.reg_funcs.nsH","title":"<code>grins.reg_funcs.nsH(nod, fld, thr, hill)</code>","text":"<p>Negative Shifted Hill function.</p> <p>Parameters:</p> <ul> <li> <code>nod</code>               (<code>float</code>)           \u2013            <p>The node expression value.</p> </li> <li> <code>fld</code>               (<code>float</code>)           \u2013            <p>The fold change.</p> </li> <li> <code>thr</code>               (<code>float</code>)           \u2013            <p>The half-maximal threshold value.</p> </li> <li> <code>hill</code>               (<code>float</code>)           \u2013            <p>The hill coefficient.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The value of the Negative Shifted Hill function.</p> </li> </ul> Source code in <code>grins/reg_funcs.py</code> <pre><code>def nsH(nod, fld, thr, hill):\n    \"\"\"\n    Negative Shifted Hill function.\n\n    Parameters\n    ----------\n    nod : float\n        The node expression value.\n    fld : float\n        The fold change.\n    thr : float\n        The half-maximal threshold value.\n    hill : float\n        The hill coefficient.\n\n    Returns\n    -------\n    float\n        The value of the Negative Shifted Hill function.\n    \"\"\"\n    return fld + (1 - fld) * (1 / (1 + (nod / thr) ** hill))\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_diffrax_ode.gen_diffrax_odesys","title":"<code>grins.gen_diffrax_ode.gen_diffrax_odesys(topo_df, topo_name, save_dir='.')</code>","text":"<p>Generate the ODE system code for diffrax based on the given topology dataframe.</p> <p>Args:     topo_df (pandas.DataFrame): The topology dataframe containing the edges information.     topo_name (str): The name of the topology.     save_dir (str, optional): The directory to save the generated code. Defaults to \".\".</p> <p>Returns:     None:  Saves the generated file in the driectory specified by save_dir.</p> Source code in <code>grins/gen_diffrax_ode.py</code> <pre><code>def gen_diffrax_odesys(topo_df, topo_name, save_dir=\".\"):\n    \"\"\"\n    Generate the ODE system code for diffrax based on the given topology dataframe.\n\n    Args:\n        topo_df (pandas.DataFrame): The topology dataframe containing the edges information.\n        topo_name (str): The name of the topology.\n        save_dir (str, optional): The directory to save the generated code. Defaults to \".\".\n\n    Returns:\n        None:  Saves the generated file in the driectory specified by save_dir.\n    \"\"\"\n    # Get the list of parameters, target nodes and source nodes\n    param_names_list, target_nodes, source_nodes = gen_param_names(topo_df)\n    # List of unique nodes\n    unique_nodes = sorted(set(target_nodes + source_nodes))\n    # Inititalise a list to store the ODE strings\n    ode_list = [\n        \"import grins.reg_funcs as regfn\\n\",\n        \"def odesys(t,y,args):\",\n        f\"\\t({', '.join(unique_nodes)}) = y\",\n        f\"\\t({', '.join(param_names_list)}) = args\",\n    ]\n    # Loop through the target nodes\n    for ni, nod in enumerate(unique_nodes):\n        # Get the edges where n is the target node\n        target_edges = topo_df[topo_df[\"Target\"] == nod]\n        # The diffrax ODE for each node is d_&lt;nod&gt; = &lt;ODE&gt;\n        ode_list.append(\"\\t\" + f\"d_{nod} = {gen_node_ode(target_edges, nod)}\")\n    # Append the d_y line\n    ode_list.append(f\"\\td_y = ({', '.join([f'd_{nod}' for nod in unique_nodes])})\")\n    # Append the end line\n    ode_list.append(\"\\treturn d_y\\n\")\n    # Write the lines to a file\n    with open(f\"{save_dir}/{topo_name}.py\", \"w\") as f:\n        f.write(\"\\n\".join(ode_list))\n</code></pre>"},{"location":"api/RACIPE/#parameters-and-intial-conditions-generation-functions","title":"Parameters and Intial Conditions Generation Functions","text":""},{"location":"api/RACIPE/#grins.gen_params.parse_topos","title":"<code>grins.gen_params.parse_topos(topofile, save_cleaned=False)</code>","text":"<p>Parse and cleans the given topofile and return the dataframe. It is expeced that the topo files is a tab-separated file with three columns: Source, Target, and Type. White spaces can also be used to separate the columns.</p> <p>For nodes that are not alphanumeric, the function will replace the non-alphanumeric characters with an underscore and prepend \"Node_\" if the node name does not start with an alphabet. The cleaned topology file will be saved if the save_cleaned flag is set to True.</p> <p>Parameters:</p> <ul> <li> <code>topofile</code>               (<code>str</code>)           \u2013            <p>The path to the topofile.</p> </li> <li> <code>save_cleaned</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, save the cleaned topology file. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>topo_df</code> (              <code>DataFrame</code> )          \u2013            <p>The parsed dataframe.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def parse_topos(topofile: str, save_cleaned: bool = False) -&gt; pd.DataFrame:\n    \"\"\"\n    Parse and cleans the given topofile and return the dataframe. It is expeced that the topo files is a tab-separated file with three columns: Source, Target, and Type. White spaces can also be used to separate the columns.\n\n    For nodes that are not alphanumeric, the function will replace the non-alphanumeric characters with an underscore and prepend \"Node_\" if the node name does not start with an alphabet. The cleaned topology file will be saved if the save_cleaned flag is set to True.\n\n    Parameters\n    ----------\n    topofile : str\n        The path to the topofile.\n    save_cleaned : bool, optional\n        If True, save the cleaned topology file. Defaults to False.\n\n    Returns\n    -------\n    topo_df : pd.DataFrame\n        The parsed dataframe.\n    \"\"\"\n    topo_df = pd.read_csv(topofile, sep=r\"\\s+\")\n    if topo_df.shape[1] != 3:\n        raise ValueError(\n            \"The topology file should have three columns: Source, Target, and Type.\"\n        )\n    if not all(col in topo_df.columns for col in [\"Source\", \"Target\", \"Type\"]):\n        raise ValueError(\n            \"The topology file should have the columns: Source, Target, and Type.\"\n        )\n    topo_df = topo_df[[\"Source\", \"Target\", \"Type\"]]\n    # Clean up node names: replace non-alphanumerics and prepend \"Node_\" if needed.\n    topo_df[\"Source\"] = (\n        topo_df[\"Source\"]\n        .str.replace(r\"\\W\", \"_\", regex=True)\n        .apply(lambda x: f\"Node_{x}\" if not x[0].isalpha() else x)\n    )\n    topo_df[\"Target\"] = (\n        topo_df[\"Target\"]\n        .str.replace(r\"\\W\", \"_\", regex=True)\n        .apply(lambda x: f\"Node_{x}\" if not x[0].isalpha() else x)\n    )\n    if topo_df[\"Type\"].nunique() &gt; 2:\n        raise ValueError(f\"Check the topo file: {topofile}\")\n    if save_cleaned:\n        topo_df.to_csv(\n            topofile.replace(\".topo\", \"_cleaned.topo\"), sep=\"\\t\", index=False\n        )\n    return topo_df\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_params.gen_param_names","title":"<code>grins.gen_params.gen_param_names(topo_df)</code>","text":"<p>Generate parameter names based on the given topology dataframe.</p> <p>Parameters:</p> <ul> <li> <code>topo_df</code>               (<code>DataFrame</code>)           \u2013            <p>The topology dataframe containing the information about the nodes and edges.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>A tuple containing the parameter names, unique target node names, and unique source node names.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def gen_param_names(topo_df: pd.DataFrame) -&gt; Tuple[List[str], List[str], List[str]]:\n    \"\"\"\n    Generate parameter names based on the given topology dataframe.\n\n    Parameters\n    ----------\n    topo_df : pd.DataFrame\n        The topology dataframe containing the information about the nodes and edges.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the parameter names, unique target node names, and unique source node names.\n    \"\"\"\n    target_nodes = list(topo_df[\"Target\"].unique())\n    source_nodes = list(topo_df[\"Source\"].unique())\n    unique_nodes = sorted(set(source_nodes + target_nodes))\n    param_names = [f\"Prod_{n}\" for n in unique_nodes] + [\n        f\"Deg_{n}\" for n in unique_nodes\n    ]\n    for tn in unique_nodes:\n        sources = topo_df[topo_df[\"Target\"] == tn][\"Source\"].sort_values()\n        for sn, p in it.product(sources, [\"Fld\", \"Thr\", \"Hill\"]):\n            param_names.append(\n                f\"{p}_{sn}_{tn}\" if p != \"Fld\" else _get_regtype(sn, tn, topo_df)\n            )\n    return param_names, target_nodes, source_nodes\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_params.sample_distribution","title":"<code>grins.gen_params.sample_distribution(method, dimension, num_points, std_dev=None, optimise=False)</code>","text":"<p>Generates a sample distribution based on the specified method.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str</code>)           \u2013            <p>The sampling method to use. Options are \"Sobol\", \"LHS\", \"Uniform\", \"LogUniform\", \"Normal\", \"LogNormal\".</p> </li> <li> <code>dimension</code>               (<code>int</code>)           \u2013            <p>The number of dimensions for the sample points.</p> </li> <li> <code>num_points</code>               (<code>int</code>)           \u2013            <p>The number of sample points to generate.</p> </li> <li> <code>std_dev</code>               (<code>Optional[float]</code>, default:                   <code>None</code> )           \u2013            <p>The standard deviation for the \"Normal\" and \"LogNormal\" distributions. Defaults to 1.0 if not provided.</p> </li> <li> <code>optimise</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to optimise the sampling process. Applicable for \"Sobol\" and \"LHS\" methods.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>An array of sample points generated according to the specified method.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown sampling method is specified.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def sample_distribution(\n    method: str,\n    dimension: int,\n    num_points: int,\n    std_dev: Optional[float] = None,\n    optimise: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Generates a sample distribution based on the specified method.\n\n    Parameters\n    ----------\n    method : str\n        The sampling method to use. Options are \"Sobol\", \"LHS\", \"Uniform\", \"LogUniform\", \"Normal\", \"LogNormal\".\n    dimension : int\n        The number of dimensions for the sample points.\n    num_points : int\n        The number of sample points to generate.\n    std_dev : Optional[float], optional\n        The standard deviation for the \"Normal\" and \"LogNormal\" distributions. Defaults to 1.0 if not provided.\n    optimise : bool, optional\n        Whether to optimise the sampling process. Applicable for \"Sobol\" and \"LHS\" methods.\n\n    Returns\n    -------\n    np.ndarray\n        An array of sample points generated according to the specified method.\n\n    Raises\n    ------\n    ValueError\n        If an unknown sampling method is specified.\n    \"\"\"\n    if method == \"Sobol\":\n        dist_arr = _gen_sobol_seq(dimension, num_points, optimise)\n        # return _gen_sobol_seq(dimension, num_points, optimise)\n    elif method == \"LHS\":\n        dist_arr = _gen_latin_hypercube(dimension, num_points, optimise)\n        # return _gen_latin_hypercube(dimension, num_points, optimise)\n    elif method == \"Uniform\":\n        dist_arr = _gen_uniform_seq(dimension, num_points)\n        # return _gen_uniform_seq(dimension, num_points)\n    elif method == \"LogUniform\":\n        dist_arr = _gen_loguniform_seq(dimension, num_points)\n        # return _gen_loguniform_seq(dimension, num_points)\n    elif method == \"Normal\":\n        dist_arr = _gen_normal(\n            dimension, num_points, std_dev if std_dev is not None else 1.0\n        )\n        # return _gen_normal(\n        #     dimension, num_points, std_dev if std_dev is not None else 1.0\n        # )\n    elif method == \"LogNormal\":\n        dist_arr = _gen_lognormal(\n            dimension, num_points, std_dev if std_dev is not None else 1.0\n        )\n        # return _gen_lognormal(\n        #     dimension, num_points, std_dev if std_dev is not None else 1.0\n        # )\n    else:\n        raise ValueError(f\"Unknown sampling method: {method}\")\n    # Shuffle the array to avoid the correlation between the parameters\n    return np.random.permutation(dist_arr.flatten()).reshape(dist_arr.shape)\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_params.get_thr_ranges","title":"<code>grins.gen_params.get_thr_ranges(source_node, topo_df, prange_df, num_params=2 ** 10)</code>","text":"<p>Calculate the median threshold range for a given source node.</p> <p>Parameters:</p> <ul> <li> <code>source_node</code>               (<code>str</code>)           \u2013            <p>The source node for which the threshold range is calculated.</p> </li> <li> <code>topo_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the topology information.</p> </li> <li> <code>prange_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the parameter ranges.</p> </li> <li> <code>num_params</code>               (<code>int</code>, default:                   <code>2 ** 10</code> )           \u2013            <p>Number of parameters to sample. Defaults to 1024.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The median threshold range for the given source node.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def get_thr_ranges(\n    source_node: str,\n    topo_df: pd.DataFrame,\n    prange_df: pd.DataFrame,\n    num_params: int = 2**10,\n    # optimise: bool = False,\n) -&gt; float:\n    \"\"\"\n    Calculate the median threshold range for a given source node.\n\n    Parameters\n    ----------\n    source_node : str\n        The source node for which the threshold range is calculated.\n    topo_df : pd.DataFrame\n        DataFrame containing the topology information.\n    prange_df : pd.DataFrame\n        DataFrame containing the parameter ranges.\n    num_params : int, optional\n        Number of parameters to sample. Defaults to 1024.\n\n    Returns\n    -------\n    float\n        The median threshold range for the given source node.\n    \"\"\"\n    # Get the production and degradation rates for the source node\n    sn_params = prange_df[\n        prange_df[\"Parameter\"].str.contains(f\"Prod_{source_node}|Deg_{source_node}\")\n    ]\n    # Sample the production and degradation rates for the source node\n    sn_gk = sample_param_df(sn_params, num_params)\n    # Calculate the g/k values for the source node\n    sn_gk_n = (sn_gk[f\"Prod_{source_node}\"] / sn_gk[f\"Deg_{source_node}\"]).to_numpy()\n    # Get the incoming edges for the source node\n    in_edge_topo = topo_df[topo_df[\"Target\"] == source_node]\n    # If there are incoming edges, calculate the updated g/k values based on the Hills equation\n    if not in_edge_topo.empty:\n        isn = \"|\".join(in_edge_topo[\"Source\"].unique())\n        # Get the parameters for the incoming edges\n        in_edge_params = prange_df[\n            prange_df[\"Parameter\"].str.contains(\n                f\"Fld_{isn}_{source_node}|Thr_{isn}_{source_node}|Hill_{isn}_{source_node}\"\n            )\n            | prange_df[\"Parameter\"].str.contains(f\"Prod_{isn}|Deg_{isn}\")\n        ]\n        # Sample the parameters for the incoming edges\n        isn_gk = sample_param_df(\n            in_edge_params[in_edge_params[\"Parameter\"].str.contains(\"Prod_|Deg_\")],\n            num_params,\n        )\n        # Calculate the updated g/k values based on the Hills equation for the incoming edges\n        for in_node in in_edge_topo[\"Source\"].unique():\n            # print(f\"Processing incoming edge from {in_node} to {source_node}\")\n            in_gk = isn_gk[f\"Prod_{in_node}\"] / isn_gk[f\"Deg_{in_node}\"]\n            in_gk_median = np.median(in_gk)\n            # print(f\"Median g/k value for {in_node}: {in_gk_median}\")\n            in_edge_params.loc[\n                in_edge_params[\"Parameter\"].str.contains(\n                    f\"Thr_{in_node}_{source_node}\"\n                ),\n                [\"Minimum\", \"Maximum\"],\n            ] = [0.02 * in_gk_median, 1.98 * in_gk_median]\n        # Update the g/k values for the source node based on the incoming edges and return the median g/k value\n        return _get_updated_gkn_hills(sn_gk_n, in_edge_params, in_edge_topo, num_params)\n    else:\n        # If there are no incoming edges, return the median g/k value for the source node\n        return np.median(sn_gk[f\"Prod_{source_node}\"] / sn_gk[f\"Deg_{source_node}\"])\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_params.gen_param_range_df","title":"<code>grins.gen_params.gen_param_range_df(topo_df, num_params=2 ** 10, sampling_method='Sobol', thr_rows=True)</code>","text":"<p>Generate a parameter range DataFrame from the topology DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>topo_df</code>               (<code>DataFrame</code>)           \u2013            <p>The topology DataFrame containing the network structure.</p> </li> <li> <code>num_params</code>               (<code>int</code>, default:                   <code>2 ** 10</code> )           \u2013            <p>The number of parameters to generate. Default is 1024.</p> </li> <li> <code>sampling_method</code>               (<code>Union[str, dict]</code>, default:                   <code>'Sobol'</code> )           \u2013            <p>The sampling method to use. Can be a string specifying a single method for all parameters or a dictionary specifying methods for individual parameters. Default is \"Sobol\".</p> </li> <li> <code>thr_rows</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to add threshold rows to the DataFrame. Default is True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>A DataFrame containing the parameter ranges and sampling methods.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def gen_param_range_df(\n    topo_df: pd.DataFrame,\n    num_params: int = 2**10,\n    sampling_method: Union[str, dict] = \"Sobol\",\n    thr_rows: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate a parameter range DataFrame from the topology DataFrame.\n\n    Parameters\n    ----------\n    topo_df : pd.DataFrame\n        The topology DataFrame containing the network structure.\n    num_params : int, optional\n        The number of parameters to generate. Default is 1024.\n    sampling_method : Union[str, dict], optional\n        The sampling method to use. Can be a string specifying a single method for all parameters or a dictionary specifying methods for individual parameters. Default is \"Sobol\".\n    thr_rows : bool, optional\n        Whether to add threshold rows to the DataFrame. Default is True.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the parameter ranges and sampling methods.\n    \"\"\"\n    # Generate the parameter names, target nodes, and source nodes\n    param_names, target_nodes, source_nodes = gen_param_names(topo_df)\n    # Create a DataFrame to store the parameter ranges\n    prange_df = pd.DataFrame({\"Parameter\": param_names})\n    # Set the default minimum and maximum values for the parameters\n    prange_df.loc[\n        prange_df[\"Parameter\"].str.contains(\"Prod_\"), [\"Minimum\", \"Maximum\"]\n    ] = [1.0, 100.0]\n    prange_df.loc[\n        prange_df[\"Parameter\"].str.contains(\"Deg_\"), [\"Minimum\", \"Maximum\"]\n    ] = [0.1, 1.0]\n    prange_df.loc[\n        prange_df[\"Parameter\"].str.contains(\"ActFld_\"), [\"Minimum\", \"Maximum\"]\n    ] = [1.0, 100.0]\n    prange_df.loc[\n        prange_df[\"Parameter\"].str.contains(\"InhFld_\"), [\"Minimum\", \"Maximum\"]\n    ] = [0.01, 1.0]\n    prange_df.loc[\n        prange_df[\"Parameter\"].str.contains(\"Hill\"), [\"Minimum\", \"Maximum\"]\n    ] = [1.0, 6.0]\n    # Set the sampling method for each parameter, if the sampling method is a dictionary set the specific method for the specified parameters\n    if isinstance(sampling_method, str):\n        prange_df[\"Sampling\"] = sampling_method\n        if sampling_method in [\"Normal\", \"LogNormal\"]:\n            prange_df[\"StdDev\"] = 1.0\n    else:\n        for param, method in sampling_method.items():\n            prange_df.loc[prange_df[\"Parameter\"].str.contains(param), \"Sampling\"] = (\n                method\n            )\n        # If the sampling method is not specified for a parameter, set it to \"Sobol\"\n        prange_df[\"Sampling\"] = prange_df[\"Sampling\"].fillna(\"Sobol\")\n        if any(prange_df[\"Sampling\"].isin([\"Normal\", \"LogNormal\"])):\n            prange_df[\"StdDev\"] = 1.0\n    # Fill the threshold rows of the parameter range DataFrame\n    if thr_rows:\n        prange_df = add_thr_rows(prange_df, topo_df, num_params)\n    return prange_df\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_params.gen_param_df","title":"<code>grins.gen_params.gen_param_df(prange_df=None, num_params=2 ** 10, topo_df=None, sampling_method='Sobol', thr_rows=True)</code>","text":"<p>Generate the final parameter DataFrame by sampling parameters. Parameters are grouped by their 'Sampling' (and 'StdDev' if present) to ensure that parameters in the same group follow the same distribution in the higher dimensions. The final DataFrame columns are arranged in the same order as in prange_df. The sampling methods can be: 'Sobol', 'LHS', 'Uniform', 'LogUniform', 'Normal', 'LogNormal'.</p> <p>Parameters:</p> <ul> <li> <code>prange_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>DataFrame with columns [\"Parameter\", \"Minimum\", \"Maximum\", \"Sampling\", ...].</p> </li> <li> <code>num_params</code>               (<code>int</code>, default:                   <code>2 ** 10</code> )           \u2013            <p>Number of samples to generate per parameter. Default is 1024.</p> </li> <li> <code>topo_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>DataFrame containing the network topology information.</p> </li> <li> <code>sampling_method</code>               (<code>Union[str, dict]</code>, default:                   <code>'Sobol'</code> )           \u2013            <p>The sampling method to use. Can be a string specifying a single method for all parameters or a dictionary specifying methods for individual parameters. Default is \"Sobol\". The methods can be: 'Sobol', 'LHS', 'Uniform', 'LogUniform', 'Normal', 'LogNormal'.</p> </li> <li> <code>thr_rows</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to add threshold rows to the DataFrame. Default is True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame of sampled and scaled parameters.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def gen_param_df(\n    prange_df: pd.DataFrame = None,\n    num_params: int = 2**10,\n    topo_df: pd.DataFrame = None,\n    sampling_method: Union[str, dict] = \"Sobol\",\n    thr_rows: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate the final parameter DataFrame by sampling parameters.\n    Parameters are grouped by their 'Sampling' (and 'StdDev' if present) to ensure\n    that parameters in the same group follow the same distribution in the higher dimensions.\n    The final DataFrame columns are arranged in the same order as in prange_df.\n    The sampling methods can be: 'Sobol', 'LHS', 'Uniform', 'LogUniform', 'Normal', 'LogNormal'.\n\n    Parameters\n    ----------\n    prange_df : pd.DataFrame, optional\n        DataFrame with columns [\"Parameter\", \"Minimum\", \"Maximum\", \"Sampling\", ...].\n    num_params : int, optional\n        Number of samples to generate per parameter. Default is 1024.\n    topo_df : pd.DataFrame, optional\n        DataFrame containing the network topology information.\n    sampling_method : Union[str, dict], optional\n        The sampling method to use. Can be a string specifying a single method for all parameters or a dictionary specifying methods for individual parameters. Default is \"Sobol\". The methods can be: 'Sobol', 'LHS', 'Uniform', 'LogUniform', 'Normal', 'LogNormal'.\n    thr_rows : bool, optional\n        Whether to add threshold rows to the DataFrame. Default is True.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame of sampled and scaled parameters.\n    \"\"\"\n    # If the parameter range dataframe is not given\n    if prange_df is None:\n        # Generating the parameter range dataframe from the topology of the network\n        prange_df = gen_param_range_df(\n            topo_df=topo_df,\n            num_params=num_params,\n            sampling_method=sampling_method,\n            thr_rows=thr_rows,\n        )\n    # # Get the ordered parameter names\n    # ordered_params = prange_df[\"Parameter\"].tolist()\n    # # Dictionary to store sampled values for each parameter\n    # sampled_dict = {}\n\n    # # Group by 'Sampling' and 'StdDev' columns\n    # grouping_cols = [\"Sampling\"]\n    # if \"StdDev\" in prange_df.columns:\n    #     grouping_cols.append(\"StdDev\")\n\n    # # Iterate over the groups and sample the parameters\n    # for _, group in prange_df.groupby(grouping_cols, sort=False):\n    #     method = group[\"Sampling\"].iloc[0]\n    #     std_val = group[\"StdDev\"].iloc[0] if \"StdDev\" in group.columns else None\n    #     dims = group.shape[0]\n    #     samples = sample_distribution(method, dims, num_paras, std_dev=std_val)\n    #     group_sorted = group.sort_index().reset_index(drop=True)\n    #     for i, row in group_sorted.iterrows():\n    #         param_name = row[\"Parameter\"]\n    #         min_val = row[\"Minimum\"]\n    #         max_val = row[\"Maximum\"]\n    #         col_samples = samples[:, i]\n    #         if \"Hill\" in param_name:\n    #             scaled = np.ceil(max_val * col_samples)\n    #         elif \"InhFld\" in param_name:\n    #             inv_min = 1 / max_val\n    #             inv_max = 1 / min_val\n    #             scaled = 1 / (inv_min + (inv_max - inv_min) * col_samples)\n    #         else:\n    #             scaled = min_val + (max_val - min_val) * col_samples\n    #         sampled_dict[param_name] = scaled\n    # # Create a DataFrame from the sampled values\n    # data = {param: sampled_dict[param] for param in ordered_params}\n    # # Return the DataFrame with the original parameter order\n    # return pd.DataFrame(data, columns=ordered_params)\n    # Use the sample_param_df function to sample the parameters\n    param_df = sample_param_df(prange_df, num_params)\n    # Add the ParamNum column to the DataFrame\n    # param_df[\"ParamNum\"] = param_df.index + 1\n    param_df = param_df.assign(ParamNum=param_df.index + 1)\n    return param_df\n</code></pre>"},{"location":"api/RACIPE/#grins.gen_params.gen_init_cond","title":"<code>grins.gen_params.gen_init_cond(topo_df, num_init_conds=2 ** 10)</code>","text":"<p>Generate initial conditions for each node based on the topology.</p> <p>Parameters:</p> <ul> <li> <code>topo_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the topology information.</p> </li> <li> <code>num_init_conds</code>               (<code>int</code>, default:                   <code>2 ** 10</code> )           \u2013            <p>Number of initial conditions to generate. Default is 2**10.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame containing the generated initial conditions for each node.</p> </li> </ul> Source code in <code>grins/gen_params.py</code> <pre><code>def gen_init_cond(topo_df: pd.DataFrame, num_init_conds: int = 2**10) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate initial conditions for each node based on the topology.\n\n    Parameters\n    ----------\n    topo_df : pd.DataFrame\n        DataFrame containing the topology information.\n    num_init_conds : int, optional\n        Number of initial conditions to generate. Default is 2**10.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing the generated initial conditions for each node.\n    \"\"\"\n    _, target_nodes, source_nodes = gen_param_names(topo_df)\n    unique_nodes = sorted(set(source_nodes + target_nodes))\n    init_conds = _gen_sobol_seq(len(unique_nodes), num_init_conds)\n    # Scale initial conditions between 1 and 100\n    init_conds = 1 + init_conds * (100 - 1)\n    initcond_df = pd.DataFrame(init_conds, columns=unique_nodes)\n    # A new columns for the intial condition numbers\n    # initcond_df[\"InitCondNum\"] = initcond_df.index + 1\n    initcond_df = initcond_df.assign(InitCondNum=initcond_df.index + 1)\n    return initcond_df\n</code></pre>"},{"location":"api/RACIPE/#simulation-related-functions","title":"Simulation Related Functions","text":""},{"location":"api/RACIPE/#grins.racipe_run.gen_sim_dirstruct","title":"<code>grins.racipe_run.gen_sim_dirstruct(topo_file, save_dir='.', num_replicates=3)</code>","text":"<p>Generate directory structure for simulation run.</p> <p>Parameters:</p> <ul> <li> <code>topo_file</code>               (<code>str</code>)           \u2013            <p>Path to the topo file.</p> </li> <li> <code>save_dir</code>               (<code>str</code>, default:                   <code>'.'</code> )           \u2013            <p>Directory to save the generated structure. Defaults to \".\".</p> </li> <li> <code>num_replicates</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Number of replicates to generate. Defaults to 3.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>Directory structure is created with the topo file name and three folders for the replicates.</p> </li> </ul> Source code in <code>grins/racipe_run.py</code> <pre><code>def gen_sim_dirstruct(\n    topo_file: str, save_dir: str = \".\", num_replicates: int = 3\n) -&gt; None:\n    \"\"\"\n    Generate directory structure for simulation run.\n\n    Parameters\n    -----------\n    topo_file : str\n        Path to the topo file.\n    save_dir : str, optional\n        Directory to save the generated structure. Defaults to \".\".\n    num_replicates : int, optional\n        Number of replicates to generate. Defaults to 3.\n\n    Returns\n    --------\n    None\n        Directory structure is created with the topo file name and three folders for the replicates.\n    \"\"\"\n    # Get the topo file name\n    topo_name = topo_file.split(\"/\")[-1].split(\".\")[0]\n    # Check if the folder with the name of topo file exists\n    os.makedirs(f\"{save_dir}/{topo_name}\", exist_ok=True)\n    # Move the topo file to the created folder\n    subprocess.run(\n        [\n            \"cp\",\n            topo_file,\n            f\"{save_dir}/{topo_name}/{topo_file.split('/')[-1]}\",\n        ]\n    )\n    # Make the replicate directories\n    for rep in range(1, num_replicates + 1):\n        os.makedirs(f\"{save_dir}/{topo_name}/{rep:03}\", exist_ok=True)\n    return None\n</code></pre>"},{"location":"api/RACIPE/#grins.racipe_run.gen_topo_param_files","title":"<code>grins.racipe_run.gen_topo_param_files(topo_file, save_dir='.', num_replicates=3, num_params=2 ** 10, num_init_conds=2 ** 7, sampling_method='Sobol')</code>","text":"<p>Generate parameter files for simulation.</p> <p>Parameters:</p> <ul> <li> <code>topo_file</code>               (<code>str</code>)           \u2013            <p>The path to the topo file.</p> </li> <li> <code>save_dir</code>               (<code>str</code>, default:                   <code>'.'</code> )           \u2013            <p>The directory where the parameter files will be saved. Defaults to \".\".</p> </li> <li> <code>num_params</code>               (<code>int</code>, default:                   <code>2 ** 10</code> )           \u2013            <p>The number of parameter files to generate. Defaults to 2**10.</p> </li> <li> <code>num_init_conds</code>               (<code>int</code>, default:                   <code>2 ** 7</code> )           \u2013            <p>The number of initial condition files to generate. Defaults to 2**7.</p> </li> <li> <code>sampling_method</code>               (<code>Union[str, dict]</code>, default:                   <code>'Sobol'</code> )           \u2013            <p>The method to use for sampling the parameter space. Defaults to 'Sobol'. For a finer control over the parameter generation look at the documentation of the gen_param_range_df function and gen_param_df function.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>The parameter files and initial conditions are generated and saved in the specified replicate directories.</p> </li> </ul> Source code in <code>grins/racipe_run.py</code> <pre><code>def gen_topo_param_files(\n    topo_file: str,\n    save_dir: str = \".\",\n    num_replicates: int = 3,\n    num_params: int = 2**10,\n    num_init_conds: int = 2**7,\n    sampling_method: Union[str, dict] = \"Sobol\",\n):\n    \"\"\"\n    Generate parameter files for simulation.\n\n    Parameters\n    ----------\n    topo_file : str\n        The path to the topo file.\n    save_dir : str, optional\n        The directory where the parameter files will be saved. Defaults to \".\".\n    num_params : int, optional\n        The number of parameter files to generate. Defaults to 2**10.\n    num_init_conds : int, optional\n        The number of initial condition files to generate. Defaults to 2**7.\n    sampling_method : Union[str, dict], optional\n        The method to use for sampling the parameter space. Defaults to 'Sobol'. For a finer control over the parameter generation look at the documentation of the gen_param_range_df function and gen_param_df function.\n\n    Returns\n    -------\n    None\n        The parameter files and initial conditions are generated and saved in the specified replicate directories.\n    \"\"\"\n    # Get the name of the topo file\n    topo_name = topo_file.split(\"/\")[-1].split(\".\")[0]\n    # Parse the topo file\n    topo_df = parse_topos(topo_file)\n    # # Generate the parameter names\n    # param_names = gen_param_names(topo_df)\n    # Get the unique nodes in the topo file\n    # unique_nodes = sorted(set(param_names[1] + param_names[2]))\n    # Generate the required directory structure\n    gen_sim_dirstruct(topo_file, save_dir, num_replicates)\n    # Specify directory where all the generated ode system file will be saved\n    sim_dir = f\"{save_dir}/{topo_file.split('/')[-1].split('.')[0]}\"\n    # Generate the ODE system for diffrax\n    gen_diffrax_odesys(topo_df, topo_name, sim_dir)\n    # Generate the parameter dataframe and save in each of the replicate folders\n    for rep in range(1, num_replicates + 1):\n        # Generate the parameter range dataframe\n        param_range_df = gen_param_range_df(\n            topo_df, num_params, sampling_method=sampling_method\n        )\n        # Save the parameter range dataframe\n        param_range_df.to_csv(\n            f\"{sim_dir}/{rep:03}/{topo_name}_param_range_{rep:03}.csv\",\n            index=False,\n            sep=\"\\t\",\n        )\n        # # Generate the parameter dataframe with the default values\n        param_df = gen_param_df(param_range_df, num_params)\n        # print(param_df)\n        param_df.to_parquet(\n            f\"{sim_dir}/{rep:03}/{topo_name}_params_{rep:03}.parquet\", index=False\n        )\n        # Generate the initial conditions dataframe\n        initcond_df = gen_init_cond(topo_df=topo_df, num_init_conds=num_init_conds)\n        # print(initcond_df)\n        initcond_df.to_parquet(\n            f\"{sim_dir}/{rep:03}/{topo_name}_init_conds_{rep:03}.parquet\",\n            index=False,\n        )\n    print(f\"Parameter and Intial Condition files generated for {topo_name}\")\n    return None\n</code></pre>"},{"location":"api/RACIPE/#grins.racipe_run.load_odeterm","title":"<code>grins.racipe_run.load_odeterm(topo_name, simdir)</code>","text":"<p>Loads an ODE system from a specified topology module and returns an ODETerm object.</p> <p>Parameters:</p> <ul> <li> <code>topo_name</code>               (<code>str</code>)           \u2013            <p>The name of the topology module to import.</p> </li> <li> <code>simdir</code>               (<code>str</code>)           \u2013            <p>The directory path where the topology module is located.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ODETerm</code>           \u2013            <p>An object representing the ODE system.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>             \u2013            <p>If the specified module cannot be imported.</p> </li> <li> <code>AttributeError</code>             \u2013            <p>If the module does not contain an attribute named 'odesys'.</p> </li> </ul> Source code in <code>grins/racipe_run.py</code> <pre><code>def load_odeterm(topo_name, simdir):\n    \"\"\"\n    Loads an ODE system from a specified topology module and returns an ODETerm object.\n\n    Parameters\n    ----------\n    topo_name : str\n        The name of the topology module to import.\n    simdir : str\n        The directory path where the topology module is located.\n\n    Returns\n    -------\n    ODETerm\n        An object representing the ODE system.\n\n    Raises\n    ------\n    ImportError\n        If the specified module cannot be imported.\n    AttributeError\n        If the module does not contain an attribute named 'odesys'.\n    \"\"\"\n    sys.path.append(f\"{simdir}\")\n    mod = import_module(f\"{topo_name}\")\n    term = ODETerm(getattr(mod, \"odesys\"))\n    return term\n</code></pre>"},{"location":"api/RACIPE/#grins.racipe_run.topo_simulate","title":"<code>grins.racipe_run.topo_simulate(topo_file, replicate_dir, initial_conditions, parameters, t0=0.0, tmax=200.0, dt0=0.01, tsteps=None, rel_tol=1e-05, abs_tol=1e-06, max_steps=2048, batch_size=10000, ode_term_dir=None)</code>","text":"<p>Simulates the ODE system defined by the topology file and saves the results in the replicate directory. The ode system is loaded as a diffrax ode term and the initial conditions and parameters are passed as jax arrays. The simulation is run for the specified time range and time steps and the results are saved in parquet format in the replicate directory.</p> <p>Parameters:</p> <ul> <li> <code>topo_file</code>               (<code>str</code>)           \u2013            <p>Path to the topology file.</p> </li> <li> <code>replicate_dir</code>               (<code>str</code>)           \u2013            <p>Directory where the replicate results will be saved.</p> </li> <li> <code>initial_conditions</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the initial conditions.</p> </li> <li> <code>parameters</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the parameters.</p> </li> <li> <code>t0</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Initial time for the simulation. Default is 0.0.</p> </li> <li> <code>tmax</code>               (<code>float</code>, default:                   <code>200.0</code> )           \u2013            <p>Maximum time for the simulation. Default is 100.0.</p> </li> <li> <code>dt0</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Initial time step size. Default is 0.1.</p> </li> <li> <code>tsteps</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of time steps at which to save the results. Default is None.</p> </li> <li> <code>rel_tol</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>Relative tolerance for the ODE solver. Default is 1e-5.</p> </li> <li> <code>abs_tol</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>Absolute tolerance for the ODE solver. Default is 1e-6.</p> </li> <li> <code>max_steps</code>               (<code>int</code>, default:                   <code>2048</code> )           \u2013            <p>Maximum number of steps for the ODE solver. Default is 2048.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>Batch size for processing combinations of initial conditions and parameters. Default is 10000.</p> </li> <li> <code>ode_term_dir</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Directory where the ODE system file is located. Default is None. If None, the parent directory of the replicate directory is assumed to contain the ODE system file. The ODE system file should be named as the topo file with the .py extension.</p> </li> </ul> Returns: <p>pd.DataFrame     DataFrame containing the solutions of the ODE system.</p> Source code in <code>grins/racipe_run.py</code> <pre><code>def topo_simulate(\n    topo_file,\n    replicate_dir,\n    initial_conditions,\n    parameters,\n    t0=0.0,\n    tmax=200.0,\n    dt0=0.01,\n    tsteps=None,\n    rel_tol=1e-5,\n    abs_tol=1e-6,\n    max_steps=2048,\n    batch_size=10000,\n    ode_term_dir=None,\n):\n    \"\"\"\n    Simulates the ODE system defined by the topology file and saves the results in the replicate directory. The ode system is loaded as a diffrax ode term and the initial conditions and parameters are passed as jax arrays. The simulation is run for the specified time range and time steps and the results are saved in parquet format in the replicate directory.\n\n    Parameters\n    ----------\n    topo_file : str\n        Path to the topology file.\n    replicate_dir : str\n        Directory where the replicate results will be saved.\n    initial_conditions : pd.DataFrame\n        DataFrame containing the initial conditions.\n    parameters : pd.DataFrame\n        DataFrame containing the parameters.\n    t0 : float, optional\n        Initial time for the simulation. Default is 0.0.\n    tmax : float, optional\n        Maximum time for the simulation. Default is 100.0.\n    dt0 : float, optional\n        Initial time step size. Default is 0.1.\n    tsteps : list, optional\n        List of time steps at which to save the results. Default is None.\n    rel_tol : float, optional\n        Relative tolerance for the ODE solver. Default is 1e-5.\n    abs_tol : float, optional\n        Absolute tolerance for the ODE solver. Default is 1e-6.\n    max_steps : int, optional\n        Maximum number of steps for the ODE solver. Default is 2048.\n    batch_size : int, optional\n        Batch size for processing combinations of initial conditions and parameters. Default is 10000.\n    ode_term_dir : str, optional\n        Directory where the ODE system file is located. Default is None. If None, the parent directory of the replicate directory is assumed to contain the ODE system file. The ODE system file should be named as the topo file with the .py extension.\n\n\n    Returns:\n    -------\n    pd.DataFrame\n        DataFrame containing the solutions of the ODE system.\n    \"\"\"\n    # Get the name of the topo file\n    topo_name = topo_file.split(\"/\")[-1].split(\".\")[0]\n    # Making sure to remove the trailing slash from the replicate directory path if it exists\n    replicate_dir = replicate_dir.rstrip(\"/\")\n    # Check if the ode term directory is None\n    if ode_term_dir is None:\n        # Getting the parent directory of the replicate directory to get the ODE system file\n        simul_dir = os.path.dirname(replicate_dir)\n        print(f\"Loading ODE system from: {simul_dir}\")\n    else:\n        # Making sure to remove the trailing slash from the ode term directory path if it exists\n        simul_dir = ode_term_dir.rstrip(\"/\")\n    # Load the ODE system as a diffrax ode term\n    ode_term = load_odeterm(topo_name, simul_dir)\n    # Getting the intial conditions dataframe column names\n    ic_columns = initial_conditions.columns\n    # Converting the initial conditions and parameters to jax arrays\n    initial_conditions = jnp.array(initial_conditions.to_numpy())\n    parameters = jnp.array(parameters.to_numpy())\n    # Get the combinations of initial conditions and parameters\n    icprm_comb = _gen_combinations(len(initial_conditions), len(parameters))\n    print(f\"Number of combinations to simulate: {len(icprm_comb)}\")\n    # Processing the time steps\n    if tsteps is None:\n        saveat = SaveAt(t1=True)\n        print(\n            f\"Running steady sate simulations for replicate: {replicate_dir.split('/')[-1]}\"\n        )\n    else:\n        # Checking if the time steps are in the correct format\n        tsteps = sorted(tsteps)\n        # If the final step more than tmax, make tmax equal to the final step\n        if tsteps[-1] != tmax:\n            tmax = tsteps[-1]\n        # Convert the time steps to a jax array\n        tsteps = jnp.array(tsteps)\n        # Make the saveat object be the time steps\n        saveat = SaveAt(ts=tsteps)\n        print(\n            f\"Running time series simulations for replicate: {replicate_dir.split('/')[-1]}\"\n        )\n    # Specifying the PID controller for the step sizes\n    stepsize_controller = PIDController(rtol=rel_tol, atol=abs_tol)\n    # Get the functions to solve the ODE system\n    solveode_fn = parameterise_solveode(\n        ode_term,\n        Tsit5(),\n        t0,\n        tmax,\n        dt0,\n        saveat,\n        stepsize_controller,\n        max_steps,\n        initial_conditions,\n        parameters,\n    )\n    # Jit compile the solveode function\n    solveode_fn = jit(solveode_fn)\n    # # # Solve for one combination of initial conditions and parameters\n    # sol = solveode_fn(icprm_comb[0])\n    # print(sol)\n    # Create an empty array to store the solutions\n    if saveat.subs.ts is None:\n        solution_matrix = np.zeros(\n            (len(icprm_comb), initial_conditions.shape[1] + 3), dtype=np.float32\n        )\n    else:\n        solution_matrix = np.zeros(\n            (len(icprm_comb) * len(saveat.subs.ts), initial_conditions.shape[1] + 2),\n            dtype=np.float32,\n        )\n    # Defining the length of the time steps to properly index the solution matrix\n    len_tsteps = len(saveat.subs.ts) if saveat.subs.ts is not None else 1\n    # Iterate over the combinations array in batches\n    for ip in range(0, len(icprm_comb), batch_size):\n        # print(ip)\n        # Get the chunk of the combinations array\n        icprm_chunk = icprm_comb[ip : ip + batch_size]\n        # vmap the solveode function over the chunk of the combinations array\n        sols = vmap(solveode_fn)(icprm_chunk)\n        # Vertically stack the solutions\n        sols = jnp.vstack(sols)\n        # Round the solutions to 4 decimal places\n        sols = jnp.round(sols, 4)\n        # print(ip * len(saveat.subs.ts), (ip * len(saveat.subs.ts)) + len(sols))\n        # Add the solutions to the solution matrix at the correct index\n        solution_matrix[ip * len_tsteps : (ip * len_tsteps) + len(sols)] = np.array(\n            sols\n        )\n    # Convert the solution matrix to a dataframe\n    # REmoving the InitCondNum column from the initial conditions\n    if saveat.subs.ts is None:\n        solution_matrix = pd.DataFrame(\n            solution_matrix,\n            columns=ic_columns[:-1].tolist()\n            + [\"Time\", \"SteadyStateFlag\", \"InitCondNum\", \"ParamNum\"],\n        )\n        # Find number of steady state solutions\n        # print(solution_matrix[\"SteadyStateFlag\"].value_counts())\n        # # Make the steady state flag, init cond and param num columns into integers\n        # solution_matrix[[\"SteadyStateFlag\", \"InitCondNum\", \"ParamNum\"]] = (\n        #     solution_matrix[[\"SteadyStateFlag\", \"InitCondNum\", \"ParamNum\"]].astype(int)\n        # )\n        # # Save the solution matrix as a parquet file\n        # solution_matrix.to_parquet(\n        #     f\"{replicate_dir}/{topo_name}_steadystate_solutions.parquet\", index=False\n        # )\n    else:\n        solution_matrix = pd.DataFrame(\n            solution_matrix,\n            columns=ic_columns[:-1].tolist() + [\"Time\", \"InitCondNum\", \"ParamNum\"],\n        )\n        # # Make the init cond and param num columns into integers\n        # solution_matrix[[\"InitCondNum\", \"ParamNum\"]] = solution_matrix[\n        #     [\"InitCondNum\", \"ParamNum\"]\n        # ].astype(int)\n        # Find number of last time points\n        # print(solution_matrix[\"Time\"].value_counts())\n        # Save the solution matrix as a parquet file\n        # solution_matrix.to_parquet(\n        #     f\"{replicate_dir}/{topo_name}_timeseries_solutions.parquet\", index=False\n        # )\n    return solution_matrix\n</code></pre>"},{"location":"api/RACIPE/#grins.racipe_run.gk_normalise_solutions","title":"<code>grins.racipe_run.gk_normalise_solutions(sol_df, param_df, threshold=1.01, discretize=True)</code>","text":"<p>Normalises the solutions in the solution dataframe using the maximum production rate (G) and degradation rate (k) parameters of the individual nodes in the parameter sets.</p> <p>Parameters:</p> <ul> <li> <code>sol_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the solutions with a <code>ParamNum</code> column to join with param_df.</p> </li> <li> <code>param_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing the parameters with <code>Prod_</code> and <code>Deg_</code> columns for each node.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>1.01</code> )           \u2013            <p>Threshold value for discretising the solutions. Default is 1.01.</p> </li> <li> <code>discretize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to discretise the solutions. Default is True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame containing the normalised and discretised solutions.</p> </li> <li> <code>DataFrame</code>           \u2013            <p>DataFrame containing the counts of each state in the normalised solutions.</p> </li> </ul> Example <p>First, run the simulation then, normalise and discretise the solutions</p> <pre><code>&gt;&gt;&gt; sol_df, state_counts = gk_normalise_solutions(sol_df, params)\n</code></pre> <p>Here, the <code>sol_df</code> is the solution dataframe and <code>params</code> is the parameter dataframe. The <code>state_counts</code> dataframe contains the counts of each state in the normalised solutions. The returned <code>sol_df</code> is the normalised and discretised solution dataframe.</p> Source code in <code>grins/racipe_run.py</code> <pre><code>def gk_normalise_solutions(sol_df, param_df, threshold=1.01, discretize=True):\n    \"\"\"\n    Normalises the solutions in the solution dataframe using the maximum production rate (G) and degradation rate (k) parameters of the individual nodes in the parameter sets.\n\n    Parameters\n    ----------\n    sol_df : pd.DataFrame\n        DataFrame containing the solutions with a `ParamNum` column to join with param_df.\n    param_df : pd.DataFrame\n        DataFrame containing the parameters with `Prod_` and `Deg_` columns for each node.\n    threshold : float, optional\n        Threshold value for discretising the solutions. Default is 1.01.\n    discretize : bool, optional\n        Whether to discretise the solutions. Default is True.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing the normalised and discretised solutions.\n    pd.DataFrame\n        DataFrame containing the counts of each state in the normalised solutions.\n\n    Example\n    -------\n    First, run the simulation then, normalise and discretise the solutions\n\n        &gt;&gt;&gt; sol_df, state_counts = gk_normalise_solutions(sol_df, params)\n\n    Here, the `sol_df` is the solution dataframe and `params` is the parameter dataframe.\n    The `state_counts` dataframe contains the counts of each state in the normalised solutions. The returned `sol_df` is the normalised and discretised solution dataframe.\n    \"\"\"\n    # Get the node columns from the solution dataframe\n    node_cols = [col.replace(\"Prod_\", \"\") for col in param_df.columns if \"Prod_\" in col]\n    # Get the production and degradation columns\n    prod_cols = [f\"Prod_{node}\" for node in node_cols]\n    deg_cols = [f\"Deg_{node}\" for node in node_cols]\n    # Get the gk columns\n    gk_cols = [f\"gk_{node}\" for node in node_cols]\n    # Compute the gk values\n    param_df[gk_cols] = param_df[prod_cols].values / param_df[deg_cols].values\n    # Join the solution dataframe with the parameter dataframe on the 'ParamNum' column\n    norm_df = sol_df.merge(param_df[gk_cols + [\"ParamNum\"]], on=\"ParamNum\")\n    # Divide the node columns by the gk columns\n    norm_df[gk_cols] = norm_df[node_cols].values / norm_df[gk_cols].values\n    if not discretize:\n        # Select the node columns and discretise the solutions\n        norm_df = pd.concat(\n            [norm_df, discretise_solutions(norm_df[gk_cols], threshold)], axis=1\n        )\n    # Drop the gk columns\n    norm_df.drop(columns=gk_cols, inplace=True)\n    # print(norm_df)\n    if discretize:\n        # Get the State columns and return the state counts\n        state_counts = norm_df[\"State\"].value_counts()\n        # Make the State column as a column\n        state_counts = state_counts.reset_index()\n        # Rename the columns\n        state_counts.columns = [\"State\", \"Count\"]\n        # Return the normalised and discretised solution dataframe\n        return norm_df, state_counts\n    else:\n        return norm_df\n</code></pre>"},{"location":"api/RACIPE/#grins.racipe_run.discretise_solutions","title":"<code>grins.racipe_run.discretise_solutions(norm_df, threshold=1.01)</code>","text":"<p>Discretises the solutions in a g/k normalized DataFrame based on histogram peaks and minima.</p> <p>Parameters:</p> <ul> <li> <code>norm_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing normalized values to be discretised.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>1.01</code> )           \u2013            <p>A hard threshold value to clip the values in the DataFrame. Default is 1.01. If the parameter sets are in such a way that the maximum possible expression of the node is not production/degradation, then the threshold value needs to be adjusted accordingly.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>A Series containing the discrete state labels for each row in the input DataFrame.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If any value in the DataFrame exceeds the specified threshold.</p> </li> </ul> Example <p>Given a normalized DataFrame <code>norm_df</code>, discretise the values</p> <pre><code>&gt;&gt;&gt; lvl_df = discretise_solutions(norm_df)\n</code></pre> <p>The normalized solution DataFrame contains values of the nodes between 0 (lowest) and 1 (highest). The returned <code>lvl_df</code> will have discrete state labels for each row in the input DataFrame.</p> Source code in <code>grins/racipe_run.py</code> <pre><code>def discretise_solutions(norm_df, threshold=1.01):\n    \"\"\"\n    Discretises the solutions in a g/k normalized DataFrame based on histogram peaks and minima.\n\n    Parameters\n    ----------\n    norm_df : pd.DataFrame\n        DataFrame containing normalized values to be discretised.\n    threshold : float, optional\n        A hard threshold value to clip the values in the DataFrame. Default is 1.01. If the parameter sets are in such a way that the maximum possible expression of the node is not production/degradation, then the threshold value needs to be adjusted accordingly.\n\n    Returns\n    -------\n    pd.Series\n        A Series containing the discrete state labels for each row in the input DataFrame.\n\n    Raises\n    ------\n    ValueError\n        If any value in the DataFrame exceeds the specified threshold.\n\n    Example\n    -------\n    Given a normalized DataFrame ```norm_df```, discretise the values\n\n        &gt;&gt;&gt; lvl_df = discretise_solutions(norm_df)\n\n    The normalized solution DataFrame contains values of the nodes between 0 (lowest) and 1 (highest).\n    The returned `lvl_df` will have discrete state labels for each row in the input DataFrame.\n\n    \"\"\"\n    # Flatten the numeric part of the dataframe (columns 4 onwards)\n    flat = norm_df.values.flatten()\n\n    # Add dummy values to ensure boundary peaks are detected\n    dummy_low = np.full(10, -0.1)\n    dummy_high = np.full(10, 1.1)\n    data_with_dummy = np.concatenate([dummy_low, flat, dummy_high])\n\n    # Compute histogram over 120 bins\n    flat_hist, bin_edges = np.histogram(data_with_dummy, bins=120)\n\n    # Define threshold for peak and minima detection (1% of data length)\n    threshold = int(len(flat) * 0.01)\n\n    # Detect peaks in the histogram\n    peaks, _ = find_peaks(\n        flat_hist,\n        height=threshold,\n        threshold=threshold,\n        prominence=threshold,\n        distance=int(len(bin_edges) * 0.1),\n    )\n    maxima_bins = bin_edges[peaks]\n\n    # Detect minima by inverting the histogram (skip first and last bin)\n    minima_indices, _ = find_peaks(\n        np.max(flat_hist) - flat_hist[1:-1], height=np.max(flat_hist) * 0.99\n    )\n    # Adjust indices (because we skipped the first bin)\n    minima_indices = [idx + 1 for idx in minima_indices]\n\n    # Initialize minima bins with the boundaries 0.0 and 1.0\n    minima_bins = [0.0, 1.0]\n\n    # For multiple peaks, find a representative (median) minimum between each adjacent pair\n    if len(maxima_bins) &gt; 1:\n        for i in range(1, len(maxima_bins)):\n            # Candidate minima between two successive peaks\n            candidates = [\n                bin_edges[idx]\n                for idx in minima_indices\n                if maxima_bins[i - 1] &lt;= bin_edges[idx] &lt;= maxima_bins[i]\n            ]\n            if candidates:\n                median_candidate = candidates[len(candidates) // 2]\n                minima_bins.append(median_candidate)\n    # If only one peak exists, take the median minimum if available\n    elif minima_indices:\n        median_candidate = bin_edges[minima_indices[len(minima_indices) // 2]]\n        minima_bins.append(median_candidate)\n\n    # Ensure the bin edges are sorted\n    minima_bins = np.sort(minima_bins)\n\n    # Clip the values to 1.0 as due to small numerical errors, some values may be slightly above 1.0\n    norm_df = norm_df.mask((norm_df &gt; 1) &amp; (norm_df &lt; threshold), 1.0)\n\n    # If any value is found to be higher than the hard threshold, raise an error\n    if (norm_df &gt; threshold).any().any():\n        raise ValueError(\n            f\"Some values exceed the hard threshold of {threshold}, check your input data.\"\n        )\n\n    # Use vectorized binning to assign each value to a discrete level\n    # The number of levels is len(minima_bins)-1 (each interval defines one level)\n    lvl_df = norm_df.apply(\n        lambda col: pd.cut(\n            col,\n            bins=minima_bins,\n            labels=range(len(minima_bins) - 1),\n            include_lowest=True,\n        )\n    )\n    lvl_df = lvl_df.add_prefix(\"Lvl_\")\n\n    # Create a 'State' column by concatenating the discrete levels as strings\n    lvl_df[\"State\"] = \"'\" + lvl_df.astype(str).apply(\"\".join, axis=1) + \"'\"\n    # print(lvl_df)\n    # Get the value counts of the states\n    # print(lvl_df[\"State\"].value_counts())\n    return lvl_df[\"State\"]\n</code></pre>"},{"location":"api/RACIPE/#grins.racipe_run.run_all_replicates","title":"<code>grins.racipe_run.run_all_replicates(topo_file, save_dir='.', t0=0.0, tmax=200.0, dt0=0.01, tsteps=None, rel_tol=1e-05, abs_tol=1e-06, max_steps=2048, batch_size=10000, normalize=True, discretize=True)</code>","text":"<p>Run simulations for all replicates of the specified topo file. The initial conditions and parameters are loaded from the replicate folders. The directory structure is assumed to be the same as that generated by the gen_topo_param_files function, with the main directory with the topo file name which has the parameter range file the ODE system file and the replicate folders with the initial conditions and parameters dataframes.</p> <p>Parameters:</p> <ul> <li> <code>topo_file</code>               (<code>str</code>)           \u2013            <p>Path to the topology file.</p> </li> <li> <code>save_dir</code>               (<code>str</code>, default:                   <code>'.'</code> )           \u2013            <p>Directory where the replicate folders are saved. Defaults to \".\".</p> </li> <li> <code>t0</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Initial time for the simulation. Defaults to 0.0.</p> </li> <li> <code>tmax</code>               (<code>float</code>, default:                   <code>200.0</code> )           \u2013            <p>Maximum time for the simulation. Defaults to 100.0.</p> </li> <li> <code>dt0</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Initial time step for the simulation. Defaults to 0.1.</p> </li> <li> <code>tsteps</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of time steps for the simulation. Defaults to None.</p> </li> <li> <code>rel_tol</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>Relative tolerance for the simulation. Defaults to 1e-5.</p> </li> <li> <code>abs_tol</code>               (<code>float</code>, default:                   <code>1e-06</code> )           \u2013            <p>Absolute tolerance for the simulation. Defaults to 1e-6.</p> </li> <li> <code>max_steps</code>               (<code>int</code>, default:                   <code>2048</code> )           \u2013            <p>Maximum number of steps for the simulation. Defaults to 2048.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>Batch size for the simulation. Defaults to 1000.</p> </li> <li> <code>normalize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to normalise the solutions. Defaults to True.</p> </li> <li> <code>discretize</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to discretize the solutions. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>The results of the simulation are saved in the replicate folders in the specified directory.</p> </li> </ul> Note <p>The results of the simulation are saved in the replicate folders in the specified directory. If the simulation is time series, the results are saved as <code>timeseries_solutions.parquet</code> and if the simulation is steady state, the results are saved as <code>steadystate_solutions.parquet</code>.</p> <p>Normalisation and discretisation of the solutions are optional. But to discretise the solutions, the normalisation is required.</p> <p>If the discretize flag is set to True, the solutions are discretized and the state counts are saved as <code>state_counts.csv</code>, this is only applicable for steady state simulations. If the discretize flag is set to False, the solutions are normalised but not discretized.</p> Example <p>Run the simulation for the specified topo file</p> <pre><code>&gt;&gt;&gt; run_all_replicates(topo_file, save_dir, t0, tmax, dt0, tsteps, rel_tol, abs_tol, max_steps, batch_size)\n</code></pre> Source code in <code>grins/racipe_run.py</code> <pre><code>def run_all_replicates(\n    topo_file,\n    save_dir=\".\",\n    t0=0.0,\n    tmax=200.0,\n    dt0=0.01,\n    tsteps=None,\n    rel_tol=1e-5,\n    abs_tol=1e-6,\n    max_steps=2048,\n    batch_size=10000,\n    normalize=True,\n    discretize=True,\n):\n    \"\"\"\n    Run simulations for all replicates of the specified topo file. The initial conditions and parameters are loaded from the replicate folders. The directory structure is assumed to be the same as that generated by the gen_topo_param_files function, with the main directory with the topo file name which has the parameter range file the ODE system file and the replicate folders with the initial conditions and parameters dataframes.\n\n    Parameters\n    ----------\n    topo_file : str\n        Path to the topology file.\n    save_dir : str, optional\n        Directory where the replicate folders are saved. Defaults to \".\".\n    t0 : float, optional\n        Initial time for the simulation. Defaults to 0.0.\n    tmax : float, optional\n        Maximum time for the simulation. Defaults to 100.0.\n    dt0 : float, optional\n        Initial time step for the simulation. Defaults to 0.1.\n    tsteps : int, optional\n        Number of time steps for the simulation. Defaults to None.\n    rel_tol : float, optional\n        Relative tolerance for the simulation. Defaults to 1e-5.\n    abs_tol : float, optional\n        Absolute tolerance for the simulation. Defaults to 1e-6.\n    max_steps : int, optional\n        Maximum number of steps for the simulation. Defaults to 2048.\n    batch_size : int, optional\n        Batch size for the simulation. Defaults to 1000.\n    normalize : bool, optional\n        Whether to normalise the solutions. Defaults to True.\n    discretize : bool, optional\n        Whether to discretize the solutions. Defaults to True.\n\n    Returns\n    -------\n    None\n        The results of the simulation are saved in the replicate folders in the specified directory.\n\n    Note\n    ----\n    The results of the simulation are saved in the replicate folders in the specified directory. If the simulation is time series, the results are saved as `timeseries_solutions.parquet` and if the simulation is steady state, the results are saved as `steadystate_solutions.parquet`.\n\n    Normalisation and discretisation of the solutions are optional. But to discretise the solutions, the normalisation is required.\n\n    If the discretize flag is set to True, the solutions are discretized and the state counts are saved as `state_counts.csv`, this is only applicable for steady state simulations. If the discretize flag is set to False, the solutions are normalised but not discretized.\n\n    Example\n    --------\n    Run the simulation for the specified topo file\n\n        &gt;&gt;&gt; run_all_replicates(topo_file, save_dir, t0, tmax, dt0, tsteps, rel_tol, abs_tol, max_steps, batch_size)\n    \"\"\"\n    # Cheking if discretize is True and normalise is False, if so turn normalise to True\n    if discretize and not normalize:\n        normalize = True\n    # Get the name of the topo file\n    topo_name = topo_file.split(\"/\")[-1].split(\".\")[0]\n    # Get the list of replicate folders\n    replicate_folders = sorted(\n        [\n            folder\n            for folder in glob(f\"{save_dir}/{topo_name}/*/\")\n            if os.path.basename(folder.rstrip(\"/\")).isdigit()\n        ],\n    )\n    # Loop through the replicate folders and run the simulation for each replicate\n    for replicate_dir in replicate_folders:\n        # Getting the base name of the replicate directory\n        replicate_base = os.path.basename(replicate_dir.rstrip(\"/\"))\n        # Load the initial conditions and parameters dataframes\n        init_cond_path = (\n            f\"{replicate_dir}/{topo_name}_init_conds_{replicate_base}.parquet\"\n        )\n        params_path = f\"{replicate_dir}/{topo_name}_params_{replicate_base}.parquet\"\n        # Read the initial conditions and parameters dataframes\n        init_conds = pd.read_parquet(init_cond_path)\n        params = pd.read_parquet(params_path)\n        # Starting the timer\n        start_time = time.time()\n        # Run the simulation for the specified topo file and given initial conditions and parameters\n        sol_df = topo_simulate(\n            topo_file=topo_file,\n            replicate_dir=replicate_dir,\n            initial_conditions=init_conds,\n            parameters=params,\n            t0=t0,\n            tmax=tmax,\n            dt0=dt0,\n            tsteps=tsteps,\n            rel_tol=rel_tol,\n            abs_tol=abs_tol,\n            max_steps=max_steps,\n            batch_size=batch_size,\n        )\n        # Ending the timer\n        print(\n            f\"Time taken for replicate {replicate_base}: {time.time() - start_time}\\n\"\n        )\n        if discretize:\n            # G/k normalise the solution dataframe\n            sol_df, state_counts = gk_normalise_solutions(\n                sol_df, params, discretize=True\n            )\n        elif normalize:\n            sol_df = gk_normalise_solutions(sol_df, params, discretize=False)\n        # Check if the time seires is given or not to name the solution file\n        if tsteps is None:\n            # Save the solution dataframe\n            sol_df.to_parquet(\n                f\"{replicate_dir}/{topo_name}_steadystate_solutions_{replicate_base}.parquet\"\n            )\n            if discretize:\n                state_counts.to_csv(\n                    f\"{replicate_dir}/{topo_name}_steadystate_state_counts_{replicate_base}.csv\",\n                    index=False,\n                    sep=\"\\t\",\n                )\n        else:\n            # Read the solution dataframe\n            sol_df.to_parquet(\n                f\"{replicate_dir}/{topo_name}_timeseries_solutions_{replicate_base}.parquet\"\n            )\n        # # break  ##################################\n    return None\n</code></pre>"},{"location":"usage/Ising_Tutorial/","title":"Ising Boolean GRN Simulation Tutorial","text":""},{"location":"usage/Ising_Tutorial/#overview","title":"Overview","text":"<p>This tutorial explains the pipeline for running Boolean simulations on gene regulatory networks (GRNs). The script processes topology files and runs simulations using different modes (synchronous and asynchronous).</p>"},{"location":"usage/Ising_Tutorial/#step-1-define-the-topology-file-directory","title":"Step 1: Define the Topology File Directory","text":"<p>We first specify the directory containing the topology files. These files define the network structure and interactions between genes.</p> <pre><code># Specify the path to the topo file\ntopo_folder = \"TOPOS\"\n</code></pre>"},{"location":"usage/Ising_Tutorial/#step-2-retrieve-topology-files","title":"Step 2: Retrieve Topology Files","text":"<p>We retrieve all topology files from the specified directory using the <code>glob</code> module. The files are sorted to ensure a consistent processing order - this sorting is not necessary.</p> <pre><code># Get the list of all the topo files\ntopo_files = sorted(glob.glob(f\"{topo_folder}/*.topo\"))\nprint(topo_files)\n</code></pre>"},{"location":"usage/Ising_Tutorial/#step-3-define-simulation-parameters","title":"Step 3: Define Simulation Parameters","text":"<p>Before running the simulations, we specify key parameters that control the simulation behavior:</p> <ul> <li>Replacement Values: The Boolean states (0 and 1) used in the simulation. Can also be (-1 and 1).</li> <li>Number of Steps: The total number of steps to simulate.</li> <li>Number of Initial Conditions: The number of different initial conditions to explore.</li> <li>Batch Size: The batch size for the simualtions, depends on the VRAM of the GPU, the function uses 'vmap' of jax to run each batch.</li> </ul> <pre><code># Specify the replacement values\nreplacement_values = jnp.array([0, 1])\n\n# Specify the number of steps to simulate\nmax_steps = 100\nprint(f\"Number of steps: {max_steps}\")\n\n# Specify the number of initial conditions to simulate\nnum_initial_conditions = 2**14\nprint(f\"Number of initial conditions: {num_initial_conditions}\")\n\n# Specify the batch size for parallel evaluation\nbatch_size = 2**10\n</code></pre>"},{"location":"usage/Ising_Tutorial/#step-4-process-topology-files-and-run-simulations","title":"Step 4: Process Topology Files and Run Simulations","text":"<p>We loop through each topology file, extract the adjacency matrix, and run simulations in both synchronous and asynchronous modes.</p> <pre><code># Loop over all the topo files\nfor topo_file in topo_files:\n    # Get the adjacency matrix and node names\n    topo_adj, node_names = parse_topo_to_matrix(topo_file)\n    print(f\"Topology: {topo_file}\")\n\n    # Run the simulation in synchronous mode\n    run_simulations(\n        topo_file=topo_file,\n        num_initial_conditions=num_initial_conditions,\n        batch_size=batch_size,\n        replacement_values=replacement_values,\n        mode=\"sync\",\n        packbits=True,\n    )\n\n    # Run the simulation in asynchronous mode\n    run_simulations(\n        topo_file=topo_file,\n        num_initial_conditions=num_initial_conditions,\n        batch_size=batch_size,\n        replacement_values=replacement_values,\n        mode=\"async\",\n        packbits=True,\n    )\n</code></pre> <p>The simulation results will be stored in the output directory, with each topology file having its own dedicated folder within the simulation directory. This folder will contain the results saved as a Parquet file named <code>&lt;topo_name&gt;_&lt;simulation_mode&gt;_ising_results.parquet</code>. For further customization options, refer to the <code>run_simulations</code> function.</p>"},{"location":"usage/RACIPE_Tutorial/","title":"RACIPE Simulation Tutorial","text":""},{"location":"usage/RACIPE_Tutorial/#overview","title":"Overview","text":"<p>This tutorial provides a comprehensive pipeline that integrates various functions for RACIPE simulations from the 'grins' library. It guides you through generating the ODE system file, parameter sets, and initial conditions, ultimately running simulations for all topology files in a specified directory containing gene regulatory network topologies.</p> <p>If more customization is needed, a similar pipeline can be built using the custom functions provided in the package\u2014this tutorial serves as a guide for structuring such workflows.</p>"},{"location":"usage/RACIPE_Tutorial/#step-1-define-the-number-if-parallel-cores-to-use","title":"Step 1: Define the number if parallel cores to use","text":"<p>We first specify the number of CPU cores to use for parallel execution. While this step is not mandatory, it significantly speeds up the parameter and initial condition generation process, making the pipeline more efficient if one is simulating a large number of networks.</p> <pre><code>numCores = 15\nprint(f\"Number of cores: {numCores}\")\n</code></pre>"},{"location":"usage/RACIPE_Tutorial/#step-2-define-directories","title":"Step 2: Define Directories","text":"<p>We define the input and output directories to organize the topology files and simulation results efficiently. The topology files, which describe the structure of gene regulatory networks, are stored in a dedicated directory (<code>TOPOS</code>). The simulation results, including generated parameter sets, initial conditions, and computed outputs, are saved in a separate directory (<code>SimulResults</code>).</p> <p>Before proceeding, we ensure that the output directory exists by using <code>os.makedirs(sim_save_dir, exist_ok=True)</code>. This command creates the directory if it does not already exist.</p> <pre><code>import os\nfrom glob import glob\n\n# Topology file directory\ntopo_dir = \"TOPOS\"\n# Directory to store simulation results\nsim_save_dir = \"SimulResults\"\n# Create output directory if it does not exist\nos.makedirs(sim_save_dir, exist_ok=True)\n</code></pre>"},{"location":"usage/RACIPE_Tutorial/#step-3-load-topology-files","title":"Step 3: Load Topology Files","text":"<p>We retrieve all topology files that need to be simulated.</p> <p>The <code>glob</code> function is used to search for all files with a <code>.topo</code> extension in the specified directory (<code>topo_dir</code>). The <code>sorted()</code> function ensures that the files are processed in a the alphbetical oder, but this is not necessary.</p> <pre><code># Get the list of all topology files which need to be simulated\ntopo_files = sorted(glob(f\"{topo_dir}/*.topo\"))\nprint(f\"Number of topology files: {len(topo_files)}\")\n</code></pre>"},{"location":"usage/RACIPE_Tutorial/#step-4-define-simulation-parameters","title":"Step 4: Define Simulation Parameters","text":"<p>Specify the number of replicates per topology file, the number of parameter sets to generate, and the number of initial conditions to be generated. These values determine the scale of the simulation:</p> <ul> <li>Replicates per topology file: The number of times each topology file will be simulated to account for variability.</li> <li>Parameter sets: The number of different sets of parameters to generate for each topology file.</li> <li>Initial conditions: The number of different initial conditions to be considered for each parameter set.</li> </ul> <p>The simulations will be run for all combinations of initial conditions and parameter sets. The standard deviation of the measured metric across all replicates is a useful indicator of how well the chosen number of parameters and initial conditions capture the dynamics of the gene regulatory network (GRN). If the standard deviation is high, increasing the number of parameter sets or initial conditions may improve the robustness of the results.</p> <pre><code>num_replicates = 3\nnum_params = 10000\nnum_init_conds = 100\nprint(f\"Number of replicates: {num_replicates}\")\nprint(f\"Number of parameters: {num_params}\")\nprint(f\"Number of initial conditions: {num_init_conds}\\n\")\n</code></pre>"},{"location":"usage/RACIPE_Tutorial/#step-5-parallelized-parameter-and-initial-condition-generation","title":"Step 5: Parallelized Parameter and Initial Condition Generation","text":"<p>We use multiprocessing to generate parameter and initial condition files in parallel. This setp is not necessary, but will significantly speed up the paramter sets and intial conditions generation time when simulating large number of networks.</p> <pre><code>from multiprocessing import Pool\n\n# Start multiprocessing pool\npool = Pool(numCores)\nprint(\"Generating Parameter and Initial Condition files...\")\n\n# Parallel execution of file generation\npool.starmap(\n    gen_topo_param_files,\n    [\n        (\n            topo_file,\n            sim_save_dir,\n            num_replicates,\n            num_params,\n            num_init_conds,\n        )\n        for topo_file in topo_files\n    ],\n)\nprint(\"Parameter and Initial Condition files generated.\\n\")\n\n# Close multiprocessing pool\npool.close()\n</code></pre>"},{"location":"usage/RACIPE_Tutorial/#step-6-running-simulations","title":"Step 6: Running Simulations","text":"<p>Once parameter files are generated, we run simulations for each topology file.</p> <pre><code>import jax.numpy as jnp\n\nfor topo_file in topo_files:\n    # Generate parameters using Sobol sampling (optional - if the paramters are not already generated in parallel)\n    gen_topo_param_files(\n        topo_file,\n        sim_save_dir,\n        num_replicates,\n        num_params,\n        num_init_conds,\n        sampling_method=\"Sobol\",\n    )\n\n    # Run time-series simulations\n    run_all_replicates(\n        topo_file,\n        sim_save_dir,\n        tsteps=jnp.array([25.0, 75.0, 100.0]),\n        max_steps=2048,\n    )\n\n    # Run steady-state simulations\n    run_all_replicates(\n        topo_file,\n        sim_save_dir,\n    )\n</code></pre> <p>The results of the simulations will be stored in the sim_save_dir, with each topology file having its own dedicated folder named after the topology file. Within these folders, the following structure will be maintained:</p>"},{"location":"usage/RACIPE_Tutorial/#topology-file-and-ode-system","title":"Topology File and ODE System","text":"<ul> <li>The original topology (.topo) file.</li> <li>The generated ODE system function using diffrax, which is created by parsing the topology file.</li> </ul>"},{"location":"usage/RACIPE_Tutorial/#replicate-subdirectories","title":"Replicate Subdirectories","text":"<p>Each topology folder will contain multiple replicate subdirectories (one per replicate). These will store:     -   Initial Conditions: Saved as a Parquet file (<code>&lt;topo_name&gt;_init_conds_&lt;replicate_number&gt;.parquet</code>).     -   Parameter Sets: Stored in another Parquet file (<code>&lt;topo_name&gt;_params_&lt;replicate_number&gt;.parquet</code>).     -   Parameter Range: A CSV file (<code>parameter_range.csv</code>) defining the parameter bounds before the simulation is run.</p>"},{"location":"usage/RACIPE_Tutorial/#simulation-output-files","title":"Simulation Output Files","text":"<p>Once the simulations are completed, the solution files will be stored in the respective replicate folders. Depending on the simulation type, the output files will follow these naming conventions:     -   Steady-state solutions: <code>&lt;topo_file_name&gt;_steady_state_solutions_&lt;replicate_number&gt;.parquet</code>     -   Time-series solutions: <code>&lt;topo_file_name&gt;_time_series_solutions_&lt;replicate_number&gt;.parquet</code>     -   Discretized State Data (if applicable): If the user has opted to discretize the states, an additional file will be present containing the unique states and their occurrence counts.</p>"}]}